{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUjMwMI8Kotk"
   },
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2023)</span>\n",
    "***\n",
    "*CE/Lecturer:* Dr **Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head Tutor:* Mr **Tuan Nguyen** | tuan.Ng@monash.edu  <br/>\n",
    "<br/>\n",
    "Department of Data Science and AI, Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V4popnCKotl"
   },
   "source": [
    "# <span style=\"color:#0b486b\">  Student Information</span>\n",
    "***\n",
    "Surname: **NG**  <br/>\n",
    "Firstname: **YI JIE**    <br/>\n",
    "Student ID: **31158145**    <br/>\n",
    "Email: **yngg0039@student.monash.edu**    <br/>\n",
    "Your tutorial time: **Monday 10:00am to 12:00pm**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXkDASf9Kotm"
   },
   "source": [
    "# <span style=\"color:#0b486b\">Deep Neural Networks</span>\n",
    "### Due: <span style=\"color:red\">11:59pm Sunday, 10 September 2023</span>  (Sunday)\n",
    "\n",
    "#### <span style=\"color:red\">Important note:</span> This is an **individual** assignment. It contributes **20%** to your final mark. Read the assignment instruction carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjYl9uH9Kotm"
   },
   "source": [
    "## <span style=\"color:#0b486b\">Instruction</span>\n",
    "\n",
    "This notebook has been prepared for you to complete Assignment 1. The theme of this assignment is about practical knowledge and skills in deep neural networks, including feedforward and convolutional neural networks. Some sections have been partially completed to help you get started. **The total marks for this notebook is 100**.\n",
    "\n",
    "* Before getting started, you should read the entire notebook carefully once to understand what you need to do. <br/>\n",
    "\n",
    "* For each cell marked with **#YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL**, there will be places where you **must** supply your own codes when instructed. <br>\n",
    "\n",
    "This assignment contains **three** parts:\n",
    "\n",
    "* **Part 1**: Questions on theory and knowledge on deep learning **[35 points], 35%**\n",
    "* **Part 2**: Coding assessment on TensorFlow for Deep Neural Networks (DNN) **[25 points], 25%**\n",
    "* **Part 3**: Coding assessment on TensorFlow for Convolution Neural Networks (CNN) **[40 points], 40%**\n",
    "\n",
    "**Hint**: This assignment was essentially designed based on the lectures and tutorials sessions covered from Week 1 to Week 5. You are strongly recommended to go through these contents thoroughly which might help you to complete this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejnZYAlwKotm"
   },
   "source": [
    "## <span style=\"color:#0b486b\">What to submit</span>\n",
    "\n",
    "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <span style=\"color:red; font-weight:bold\">single zip file, named xxx_assignment01_solution.zip</span> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqrLa-wdKotm"
   },
   "source": [
    "***For example, if your student ID is <span style=\"color:red; font-weight:bold\">12356</span>, then gather all of your assignment solution to folder, create a zip file named <span style=\"color:red; font-weight:bold\">123456_assignment01_solution.zip</span> and submit this file.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zmFDQNuKotm"
   },
   "source": [
    "Within this zip folder, you **must** submit the following files:\n",
    "1.\t**Assignment01_solution.ipynb**:  this is your Python notebook solution source file.\n",
    "1.\t**Assignment01_output.html**: this is the output of your Python notebook solution *exported* in html format.\n",
    "1.\tAny **extra files or folder** needed to complete your assignment (e.g., images used in your answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWCaucwIKotm"
   },
   "source": [
    "Since the notebook is quite big to load and work together, one recommended option is to split solution into three parts and work on them seperately. In that case, replace **Assignment01_solution.ipynb** by three notebooks: **Assignment01_Part1_solution.ipynb**, **Assignment01_Part2_solution.ipynb** and **Assignment01_Part3_solution.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU12JR7wKotn"
   },
   "source": [
    "**You can run your codes on Google Colab. In this case, you have to make a copy of your Google colab notebook including the traces and progresses of model training before submitting.**\n",
    "\n",
    "You also need to store your trained models to folder <span style=\"color:red; font-weight:bold\">*./models*</span> with recognizable file names (e.g., Part3_Sec3_2_model.h5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFhxcQ7CKotn"
   },
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: Theory and Knowledge Questions</span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 35 points]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb108MU2Kotn"
   },
   "source": [
    "The first part of this assignment is to demonstrate your knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the lectures and tutorials from weeks 1 to 3**. Going through these materials before attempting this part is highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yqu9xPJNKotn"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 1.1**</span> **Activation function plays an important role in modern Deep NNs. For each of the activation function below, state its output range, find its derivative (show your steps), and plot the activation fuction and its derivative**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span> Exponential linear unit (ELU): $\\text{ELU}(x)=\\begin{cases}\n",
    "0.1\\left(\\exp(x)-1\\right) & \\text{if}\\,x\\leq0\\\\\n",
    "x & \\text{if}\\,x>0\n",
    "\\end{cases}$\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(b)**</span> Gaussian Error Linear Unit (GELU): $\\text{GELU}(x)=x\\Phi(x)$ where $\\Phi(x)$ is the `probability cummulative function` of the standard Gaussian distribution or $\\Phi(x) = \\mathbb{P}\\left(X\\leq x\\right)$ where $X\\sim\\mathcal{N}\\left(0,1\\right)$. In addition, the GELU activation fuction (the link for the [main paper](https://arxiv.org/pdf/1606.08415v5.pdf)) has been currently widely used in the state-of-the-art Vision for Transformers (e.g., here is the link for [the main ViT paper](https://arxiv.org/pdf/2010.11929v2.pdf)).\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGvUUvUSKotn"
   },
   "source": [
    "*Your ansewers here*\n",
    "\n",
    "\n",
    "(a)\n",
    "\n",
    "when x <= 0:\n",
    "\n",
    "    maximum output  = 0.1(exp(0)-1)\n",
    "                    = 0.1(0)\n",
    "                    = 0\n",
    "                    \n",
    "    minimum output  = 0.1(exp(-∞)-1)\n",
    "                    = 0.1(-1)\n",
    "                    = -0.1\n",
    "                    \n",
    "when x > 0:\n",
    "\n",
    "    maximum output  = ∞\n",
    "    \n",
    "    minimum output  > 0\n",
    "    \n",
    "This makes the **output range** of activation function inclusively in between -0.1 and ∞ :\n",
    "\n",
    "    -0.1 <= x <= ∞ where x is the output value\n",
    "    \n",
    "   \n",
    "Deriative of activation function, ELU(x)':\n",
    "    \n",
    "    when x <= 0:\n",
    "            \n",
    "            ELU(x)'        = 0.1exp(x) - 0.1\n",
    "                \n",
    "                           = 0.1exp(x) * 1\n",
    "                           \n",
    "                           = 0.1exp(x)\n",
    "                           \n",
    "    when x > 0:\n",
    "            \n",
    "            ELU(x)' = x\n",
    "            \n",
    "                    = 1\n",
    "    \n",
    "**Output range** of ELU(x)': 0 <= x <= 1 where x is the output value of the ELU(x)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "1i-7s96iKotn",
    "outputId": "27f48077-9a6c-48ea-d825-e738cfb44dcf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Creating vectors X and Y\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y1 = []\n",
    "for i in x:\n",
    "    if i <= 0:\n",
    "        y1.append(0.1*(math.exp(i)-1))\n",
    "    else:\n",
    "        y1.append(i)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "# Create the plot\n",
    "plt.plot(x, y1,label=\"ELU(x)\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "\n",
    "# ELU(x)'\n",
    "y2 = []\n",
    "for j in x:\n",
    "    if j <= 0:\n",
    "        y2.append(0.1*(math.exp(j)))\n",
    "    else:\n",
    "        y2.append(1)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x, y2,label=\"ELU(x)'\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9x1hIE72Koto"
   },
   "source": [
    "(b)\n",
    "GELU = 0.5(x)(1+tanh(sqrt(2/pi))* (x+0.044715* x^3)))\n",
    "\n",
    "when x = -∞, tanh(x) = -1\n",
    "\n",
    "0.5(-∞) * (0) = 0\n",
    "\n",
    "when x = ∞, tanh(x) = 1\n",
    "\n",
    "0.5(∞) * (1) = ∞\n",
    "\n",
    "**output range** of GELU = 0 <= x <= ∞\n",
    "\n",
    "\n",
    "GELU' = 0.5(x)(1+tanh(((sqrt(2))(((8943x^3)/200000)+x)/sqrt(pi))))\n",
    "\n",
    "since tanh is still here, output of deriative will be the same\n",
    "\n",
    "**output range** of GELU = 0 <= x <= ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "OM9O_dnCKoto",
    "outputId": "bf258cfe-70ce-4541-9d4e-f10e16c4edca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating vectors X and Y\n",
    "X = np.linspace(-5, 5, 100)\n",
    "y1 = []\n",
    "for x in X:\n",
    "    y1.append(0.5*x*(1+(math.tanh(math.sqrt(2/(math.pi))*(x+(0.044715*(x**3)))))))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "# Create the plot\n",
    "plt.plot(X, y1,label=\"GELU(x)\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "\n",
    "# GELU(x)'\n",
    "y2 = []\n",
    "for x2 in X:\n",
    "    y2.append(0.5*x2*(1+(math.tanh((((math.sqrt(2)*(((8943*(x2**3)/200000)+x2)))/(math.sqrt(math.pi))))))))\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(X, y2,label=\"GELU(x)'\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdaUU3-zKotp"
   },
   "source": [
    "<span style=\"color:#0b486b\"> **Numpy is possibly being used in the following questions. You need to import numpy here.** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ywboxrlbKotp"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM7TlDK1Kotp"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 1.2**</span> **Assume that we feed a data point $x$ with a ground-truth label $y=3$ to the feed-forward neural network with the `ReLU activation` function as shown in the following figure**\n",
    "<img src=\"Figures/Q2_P1.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the numerical value of the latent presentation $h^1(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(b)**</span>  What is the numerical value of the latent presentation $h^2(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(c)**</span>  What is the numerical value of the logit $h^3(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(d)**</span>  What is the corresonding prediction probabilities $p(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(e)**</span>  What is the predicted label $\\hat{y}$? Is it a correct and an incorect prediction? Remind that $y=3$.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[3 point]</span></div>\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**(f)**</span>  What is the cross-entropy loss caused by the feed-forward neural network at $(x,y)$? Remind that $y=3$.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "<span style=\"color:red\">**(g)**</span>  Why the cross-entropy loss caused by the feed-forward neural network at $(x,y)$ (i.e., $\\text{CE}(1_y, p(x))$) is always non-negative? When does this $\\text{CE}(1_y, p(x))$ loss get the value $0$? Note that you need to answer this question for a general pair $(x,y)$ and a general feed-forward neural network with for example $M=4$ classes?   \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[3 point]</span></div>\n",
    "\n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69XxjYYYKotp"
   },
   "source": [
    "(a) RELU((W1 * X) + b1) where W1 is weight 1, * is dot product or matrix multiplication while b1 is bias 1.\n",
    "\n",
    "\n",
    "RELU((W1 * X) + b1) = RELU ([-1, -3.5, -6, -2])\n",
    "\n",
    "                    = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXgGY8lSKotp",
    "outputId": "63252dd9-64b0-4fc1-ca9b-7fa7a48c1512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit h1:  [-1.  -3.5 -6.  -2. ]\n",
      "h1:  [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# activation function\n",
    "def RELU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "# parameter for first layer of model\n",
    "x = np.array([1,-1,-2])\n",
    "\n",
    "W1 = np.array([[1,-1,2],[-1,0.5,1],[-2,1,2],[0,0,1]])\n",
    "b1 = np.array([1,0,1,0])\n",
    "\n",
    "# first layer\n",
    "# Wx+b\n",
    "logit_h1 = (W1.dot(x)) + b1\n",
    "print(\"logit h1: \",logit_h1)\n",
    "\n",
    "h1 = np.zeros((4))\n",
    "for i in range(len(logit_h1)):\n",
    "    h1[i] = RELU(logit_h1[i])\n",
    "\n",
    "print(\"h1: \",h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnPRZxVrKotp"
   },
   "source": [
    "(b) RELU((W2 * h1) + b1) = RELU ([0, 0.5, 1])\n",
    "\n",
    "                    = [0, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPjmetL2Kotp",
    "outputId": "cb7bc935-e25c-49be-aa97-a3f3f59758c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit h2:  [0.  0.5 1. ]\n",
      "h2:  [0.  0.5 1. ]\n"
     ]
    }
   ],
   "source": [
    "# parameter for second layer of model\n",
    "\n",
    "W2 = np.array([[-1,1,0,1],[1,1,0,-2],[0.5,-1,2,0]])\n",
    "b2 = np.array([0,0.5,1])\n",
    "\n",
    "# second layer\n",
    "# Wx+b\n",
    "logit_h2 = (W2.dot(h1)) + b2\n",
    "print(\"logit h2: \",logit_h2)\n",
    "\n",
    "h2 = np.zeros((3))\n",
    "for i in range(len(logit_h2)):\n",
    "    h2[i] = RELU(logit_h2[i])\n",
    "\n",
    "print(\"h2: \",h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfCUPQq_Kotp"
   },
   "source": [
    "(c) (W3 * h2) + b3 = [-2, 2, -0.5, 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYopw3i2Kotp",
    "outputId": "4e339703-926d-4c7e-baca-1501c452a994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h3:  [-2.   2.  -0.5  3.5]\n"
     ]
    }
   ],
   "source": [
    "# parameter for third layer of model\n",
    "W3 = np.array([[1,-2,0],[0,2,0],[1,-1,1],[0.5,1,2]])\n",
    "b3 = np.array([-1,1,-1,1])\n",
    "\n",
    "# third layer\n",
    "# Wx+b\n",
    "h3 = (W3.dot(h2)) + b3\n",
    "print(\"h3: \",h3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbGxL0yPKotp"
   },
   "source": [
    "(d) softmax(h3) = [0.00328114, 0.17914438, 0.01470507, 0.80286941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyI9V0BBKotp",
    "outputId": "71cbab40-7edc-4b27-f778-16a7cab40629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_y:  [0.00328114 0.17914438 0.01470507 0.80286941]\n"
     ]
    }
   ],
   "source": [
    "# softmax function\n",
    "def softmax(values):\n",
    "    softmax_list = np.zeros(len(values))\n",
    "    sum_values = 0\n",
    "    for x in values:\n",
    "        sum_values += (math.exp(x))\n",
    "\n",
    "    for y in range(len(values)):\n",
    "        softmax_list[y] = math.exp(values[y])/sum_values\n",
    "    return softmax_list\n",
    "\n",
    "\n",
    "predict_y = softmax(h3)\n",
    "\n",
    "print(\"predict_y: \",predict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBKlaevjKotq"
   },
   "source": [
    "(e) The predicted 𝑦̂ value takes the highest probability from softmax(h3). In this case it will be label = 4 which is wrong comparing to the truth value of label = 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MgG0kwKotq"
   },
   "source": [
    "(f) To calculate the CE loss, convert the truth value into one hot vector which indicating to the label 3 is 1, [0,0,1,0]. Calculate the CE loss between [0,0,1,0] with [0.00328114, 0.17914438, 0.01470507, 0.80286941].\n",
    "\n",
    "CE_loss = 4.219563205900562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOdgGiLYKotq",
    "outputId": "95fd7422-fd99-433d-f62b-93fe1d001ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE loss:  4.219563205900562\n"
     ]
    }
   ],
   "source": [
    "def CE_loss(one_hot, prediction):\n",
    "    CE_loss = 0\n",
    "    for x in range(len(one_hot)):\n",
    "        CE_loss += (-1 * (one_hot[x]*np.log(prediction[x])))\n",
    "    return CE_loss\n",
    "\n",
    "print(\"CE loss: \",CE_loss([0,0,1,0], predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Rott8c9Kotq"
   },
   "source": [
    "(g) Assume that we have general pair of (x,𝑦) input where x is the test data while y is the corresponding label. .We also have a general feed-forward neural network with 𝑀=4 which means x will have 4 classes or labels with corresponding probabilities of [p1,p2,p3,p4]. In this case, y will have one hot vector of [y1,y2,y3,y4] where yi = 1 = truth label and the rest will be 0.\n",
    "\n",
    "The reason why CE_loss will alawys be non negative is because from the formula itself, we have -(1/n)n∑i=1 (ln pi)(yi). The output range for ln(x) where 0<x<1 will always be negative. Therefore, -(1/n)(ln(x)) will gurantee that the CE loss is non negative.\n",
    "\n",
    "When CE loss = 0, this indicates to the prefect prediction of x and y. For instance, in one hot vector of y, yi = 1 while the prediction for x after going through the network, all probability for other classes are 0 exept pi is 1. This makes the CE loss claculation solely depends on -(1)(ln(1)) = 0.\n",
    "\n",
    "∴ CE_loss = 0 only occurs when the perfect prediction happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH927ytvKotq"
   },
   "source": [
    "For **Question 1.3**, you have two options: **(i)** *do forward, backward propagation, and SGD update for `one data example`* (**15 points**) and **(ii)** *do forward, backward propagation, and SGD update for `a batch of data examples`* (**20 points**). You can choose either **(i)** or **(ii)** to proceed.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnmsHt3pKotq"
   },
   "source": [
    "### <span style=\"color:red\">**Option 1**</span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this option: 15 points]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdNhDGuFKotq"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 1.3**</span> **Assume that we are constructing a multilayered feed-forward neural network for a classification problem with three classes where the model parameters will be generated randomly using your student ID. The architecture of this network is ($3 (Input)\\rightarrow 5(ELU) \\rightarrow 3(Output)$) as shown in the following figure. Note that the ELU has the same formula as the one in Q1.1.**\n",
    "\n",
    "<img src=\"./Figures/Q3_P1_1.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "We feed a data example $x$ with the label $y$ as shown in the figure. Answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FZ6-GA0Kotq"
   },
   "source": [
    "**You need to show both formulas, numerical results, and your numpy code for your computation for earning full marks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n9m3yWAiKotq"
   },
   "outputs": [],
   "source": [
    "#Code to generate random matrices and biases for W1, b1, W2, b2\n",
    "import numpy as np\n",
    "student_id = 31158145           #insert your student id here for example 1234\n",
    "np.random.seed(student_id)\n",
    "W1 = np.random.rand(5,3)\n",
    "b1 = np.random.rand(5,1)\n",
    "W2 = np.random.rand(3,5)\n",
    "b2 = np.random.rand(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5sbm5EQKotq"
   },
   "source": [
    "**Forward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the value of $\\bar{h}^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c60wLSliKotq"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BsdHA_bpKotr"
   },
   "outputs": [],
   "source": [
    "# Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZv9WRUnKotr"
   },
   "source": [
    "<span style=\"color:red\">**(b)**</span>  What is the value of $h^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvmPAjT-Kotr",
    "tags": []
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2AEzd_ErKotr"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2-NE6FpKotr"
   },
   "source": [
    "<span style=\"color:red\">**(c)**</span>  What is the predicted value $\\hat{y}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh5RuGofKotr"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M2bjLQWXKotr"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnCzs9TuKotr"
   },
   "source": [
    "<span style=\"color:red\">**(d)**</span>  Suppose that we use the cross-entropy (CE) loss. What is the value of the CE loss $l$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH2XxKQyKotr"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eCUps-ykKotr"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xoVdxSGKots"
   },
   "source": [
    "**Backward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(e)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{2}},\\frac{\\partial l}{\\partial W^{2}}$, and $\\frac{\\partial l}{\\partial b^{2}}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[4 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpatDIw1Kots"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8Aoiq-c5Kots"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3HlHaOnKots"
   },
   "source": [
    "<span style=\"color:red\">**(f)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{1}}, \\frac{\\partial l}{\\partial \\bar{h}^{1}},\\frac{\\partial l}{\\partial W^{1}}$, and $\\frac{\\partial l}{\\partial b^{1}}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[4 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fms1ZnJOKots"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tONUf24sKots"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAw1WorMKots"
   },
   "source": [
    "**SGD update**\n",
    "\n",
    "<span style=\"color:red\">**(g)**</span> Assume that we use SGD with learning rate $\\eta=0.01$ to update the model parameters. What are the values of $W^2, b^2$ and $W^1, b^1$ after updating?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[3 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6kQxCXHKots"
   },
   "source": [
    "*Show your fomular*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MyknfHQ6Kots"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0TR7XGOKots"
   },
   "source": [
    "### <span style=\"color:red\">**Option 2**</span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this option: 20 points]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXZG_V2oKots"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 1.3**</span> **Assume that we are constructing a multilayered feed-forward neural network for a classification problem with three classes where the model parameters will be generated randomly using your student ID. The architecture of this network is ($3 (Input)\\rightarrow 5(ELU) \\rightarrow 3(Output)$) as shown in the following figure. Note that the ELU has the same formula as the one in Q1.1.**\n",
    "\n",
    "<img src=\"./Figures/Q3_P1_2.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "We feed a batch $X$ with the labels $Y$ as shown in the figure. Note that $x^{T}$ represents the transpose vector of the vector $x$. Answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf4PicfwKott"
   },
   "source": [
    "**You need to show both formulas, numerical results, and your numpy code for your computation for earning full marks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kGz20ByPKott"
   },
   "outputs": [],
   "source": [
    "#Code to generate random matrices and biases for W1, b1, W2, b2\n",
    "import numpy as np\n",
    "student_id = 31158145           #insert your student id here for example 1234\n",
    "np.random.seed(student_id)\n",
    "W1 = np.random.rand(5,3)\n",
    "b1 = np.random.rand(5,1)\n",
    "W2 = np.random.rand(3,5)\n",
    "b2 = np.random.rand(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61SV92eZKott"
   },
   "source": [
    "**Forward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(a)**</span>  What is the value of $\\bar{h}^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Kl5e0IEKott"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "ℎ¯1(𝑥) = (Xt * W1) + b1 where W1 is weight 1, * is dot product or matrix multiplication while b1 is bias 1 and Xt is the transpose of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_JOe_K-Kott",
    "outputId": "4cf8838c-d4cb-45c0-d2d3-c8d6e0485b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0 shape: (3, 5)\n",
      "[[ 1.  -1.  -1.5 -1.   0. ]\n",
      " [-1.   2.   1.   2.   2.5]\n",
      " [ 1.  -1.   0.  -1.   1.5]]\n",
      "Weight shape: (5, 3)\n",
      "[[0.85091403 0.65172009 0.23294102]\n",
      " [0.20296634 0.32273309 0.52311136]\n",
      " [0.24261495 0.31197307 0.82205892]\n",
      " [0.92801443 0.0773592  0.73518028]\n",
      " [0.83881553 0.29063122 0.31818091]]\n",
      "logit_h1: [[ 0.46933517  0.25678534 -0.58745074  0.25678534  2.01591197]\n",
      " [ 0.90256616  0.41861006  0.51750515  0.41861006  2.09072133]\n",
      " [ 0.86092217 -0.33250637  0.05627201 -0.33250637  2.12124242]\n",
      " [ 2.19896213 -0.8953497  -0.70153583 -0.8953497   1.90929503]\n",
      " [ 1.71236922  0.27026998 -0.12158809  0.27026998  2.04985341]]\n"
     ]
    }
   ],
   "source": [
    "#Show your code\n",
    "h0 = np.array([[1,-1,1], [-1,2,-1], [-1.5,1,0], [-1,2,-1], [0,2.5,1.5]]).transpose()\n",
    "\n",
    "print(\"h0 shape: {}\".format(h0.shape))\n",
    "print(h0)\n",
    "\n",
    "print(\"Weight shape: {}\".format(W1.shape))\n",
    "print(W1)\n",
    "# Wx+b\n",
    "logit_h1 = W1.dot(h0) + b1\n",
    "# logit_h1 = (W1.dot(x)) + b1\n",
    "print(\"logit_h1: {}\".format(logit_h1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3XoRip1Kott"
   },
   "source": [
    "<span style=\"color:red\">**(b)**</span>  What is the value of $h^{1}(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSVdd7ypKott"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "ℎ1(𝑥) = ELU(ℎ¯1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obg7mkq9Kott",
    "outputId": "365597eb-b58d-4a00-de53-725d70180a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_h1: [[ 0.46933517  0.25678534 -0.04442578  0.25678534  2.01591197]\n",
      " [ 0.90256616  0.41861006  0.51750515  0.41861006  2.09072133]\n",
      " [ 0.86092217 -0.02828759  0.05627201 -0.02828759  2.12124242]\n",
      " [ 2.19896213 -0.05915353 -0.05041768 -0.05915353  1.90929503]\n",
      " [ 1.71236922  0.27026998 -0.0114487   0.27026998  2.04985341]]\n"
     ]
    }
   ],
   "source": [
    "#Show your code\n",
    "\n",
    "def ELU(x):\n",
    "    if x <= 0:\n",
    "        return (0.1*(math.exp(x)-1))\n",
    "    else:\n",
    "        return (x)\n",
    "\n",
    "h1 = np.zeros((5,5))\n",
    "\n",
    "for i in range(len(logit_h1)):\n",
    "    for j in range(len(logit_h1[0])):\n",
    "        h1[i][j] = ELU(logit_h1[i][j])\n",
    "\n",
    "print(\"logit_h1: {}\".format(h1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CN_mbdjLKott"
   },
   "source": [
    "<span style=\"color:red\">**(c)**</span>  What is the predicted value $\\hat{y}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEQbfeEjKotu"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "ℎ¯2(𝑥) = (W2 * h2) + b2\n",
    "\n",
    "𝑦 = softmax(ℎ¯2(𝑥))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWHbUkPxKotu",
    "outputId": "1a89767f-67c3-4e92-8fe5-70fa4cb613e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_y:  [[0.13730047 0.63787282 0.22482671]\n",
      " [0.31631265 0.39867892 0.28500843]\n",
      " [0.30280734 0.39728969 0.29990298]\n",
      " [0.31631265 0.39867892 0.28500843]\n",
      " [0.0822311  0.7359718  0.1817971 ]]\n"
     ]
    }
   ],
   "source": [
    "#Show your code\n",
    "h2 = (W2.dot(h1)) + b2\n",
    "h2 = h2.transpose()\n",
    "predict_y = np.zeros((5,3))\n",
    "for i in range(len(h2)):\n",
    "    predict_y[i] = softmax(h2[i])\n",
    "\n",
    "print(\"predict_y: \",predict_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWSBvrHhKotu"
   },
   "source": [
    "<span style=\"color:red\">**(d)**</span>  Suppose that we use the cross-entropy (CE) loss. What is the value of the CE loss $l$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw56kCMxKotu"
   },
   "source": [
    "*Show your formula*\n",
    "(1/n)(n∑i=1)𝐶𝐸_loss(1𝑦, 𝑝(𝑥)) = (1/n)(n∑i=1)(−𝑙𝑜𝑔(𝑝𝑦(𝑥)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7Bf6VhVKotu",
    "outputId": "ae003894-fd8c-4aba-8719-6c701a84dffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE loss:  0.8525048795716941\n"
     ]
    }
   ],
   "source": [
    "#Show your code\n",
    "\n",
    "truth_labels = np.array([[0,1,0], [1,0,0], [0,0,1], [1,0,0], [0,1,0]])\n",
    "\n",
    "total_loss = 0\n",
    "for x in range(5):\n",
    "    total_loss += (CE_loss(truth_labels[x], predict_y[x]))\n",
    "\n",
    "print(\"CE loss: \", (total_loss/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjMAt4ECKotu"
   },
   "source": [
    "**Backward propagation**\n",
    "\n",
    "<span style=\"color:red\">**(e)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{2}},\\frac{\\partial l}{\\partial W^{2}}$, and $\\frac{\\partial l}{\\partial b^{2}}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[6 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y47SuSnDKotu"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "h1' = X(W1) + b1 -> h1 = ELU(h1') -> h2 = h1(W2) + b2 -> p = softmax(h2) -> 𝑙=−𝑚𝑒𝑎𝑛(𝑦∗𝑙𝑜𝑔(𝑝)+(1−𝑦)∗𝑙𝑜𝑔(1−𝑝))\n",
    "\n",
    "    g2     = ∂𝑙/∂ℎ2  \n",
    "           = -1(m=y) + (exp(h2n)/ (n∑i=1)exp(h2i))\n",
    "           = -1y + softmax(h3)\n",
    "           = pT - 1y where pT = output of softmax while 1y will be one hot vector\n",
    "       \n",
    "    ∂𝑙/∂W2  = (∂𝑙/∂h2) (∂h2/∂W2)\n",
    "           = (g2)T (h2)T\n",
    "\n",
    "    ∂𝑙/∂b2  = (∂𝑙/∂h2) (∂h2/∂b2)\n",
    "           = (g2)T (1)\n",
    "           = (g2)T\n",
    "           \n",
    "Since the we fit a mini batch and the output of ∂𝑙/∂b2 P will be 5x5. To update and form a 5x1 bias, mean of each row from P will be calculated for bias update.\n",
    "    \n",
    "    ∂𝑙/∂b2 = ((∂𝑙/∂b2)i / 5)) where i is the row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "karY1vhFKotu"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "# g2 / ∂𝑙/∂ℎ2\n",
    "g2 = (predict_y - truth_labels)\n",
    "\n",
    "# ∂𝑙/∂W2\n",
    "der_l_W2 = (g2.transpose()).dot((h1.transpose()))\n",
    "\n",
    "# ∂𝑙/∂b2\n",
    "der_l_b2_batch = g2.transpose()\n",
    "der_l_b2 = np.zeros((3,1))\n",
    "for k in range(3):\n",
    "    der_l_b2[k] = np.sum(der_l_b2_batch[k])/5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qg6OfpB-Kotu"
   },
   "source": [
    "<span style=\"color:red\">**(f)**</span> What are the derivatives $\\frac{\\partial l}{\\partial h^{1}}, \\frac{\\partial l}{\\partial \\bar{h}^{1}},\\frac{\\partial l}{\\partial W^{1}}$, and $\\frac{\\partial l}{\\partial b^{1}}$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[6 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8dNFopuKotv"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "           \n",
    "    h2     = (W2)(h1) + b2\n",
    "    \n",
    "    g1     = (∂𝑙/∂ℎ1)\n",
    "           = (∂l/∂ℎ2)(∂h2/∂ℎ1)\n",
    "           = (g2)(w2)\n",
    "           \n",
    "    h1     = ELU(ℎ¯1)\n",
    "    ∂h1/∂ℎ¯1 = ELU'(ℎ¯1)\n",
    "    \n",
    "    g¯1    = (∂𝑙/∂ℎ¯1)\n",
    "           = (∂𝑙/∂ℎ1)(∂h1/∂ℎ¯1)\n",
    "           = g1(ELU'(ℎ¯1))\n",
    "    \n",
    "    \n",
    "    h¯1     = W1(h0) + b1\n",
    "       \n",
    "    ∂𝑙/∂W1  = (∂𝑙/∂h1) (∂h¯1/∂W1)\n",
    "           = (g¯1)T (h0)T\n",
    "\n",
    "    ∂𝑙/∂b1  = (∂𝑙/∂h¯1) (∂h¯1/∂b1)\n",
    "           = (g¯1)T (1)\n",
    "           = (g¯1)T\n",
    "           \n",
    "Since the we fit a mini batch and the output of ∂𝑙/∂b1 P will be 5x5. To update and form a 5x1 bias, mean of each row from P will be calculated for bias update.\n",
    "    \n",
    "    ∂𝑙/∂b1 = ((∂𝑙/∂b1)i / 5)) where i is the row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0BGRboXKotv",
    "outputId": "1e3997e3-a594-49ca-fb5c-1e62ead4ea42"
   },
   "outputs": [],
   "source": [
    "#Show your code\n",
    "\n",
    "# ELU(x)'\n",
    "def ELU_der(x):\n",
    "    if x <= 0:\n",
    "        return (0.1*(math.exp(x)))\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "g1 = g2.dot(W2)\n",
    "\n",
    "der_h1_logit_h = np.zeros((5,5))\n",
    "\n",
    "for x in range(5):\n",
    "    for y in range(5):\n",
    "        der_h1_logit_h[x][y] = ELU_der(logit_h1[x][y])\n",
    "\n",
    "logit_g1 = g1 * der_h1_logit_h\n",
    "\n",
    "der_l_W1 = logit_g1.transpose().dot(h0.transpose())\n",
    "\n",
    "der_l_b1_batch = logit_g1.transpose()\n",
    "\n",
    "der_l_b1 = np.zeros((5,1))\n",
    "\n",
    "for k in range(5):\n",
    "    der_l_b1[k] = np.sum(der_l_b1_batch[k])/5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD8e1eeYKotv"
   },
   "source": [
    "**SGD update**\n",
    "\n",
    "<span style=\"color:red\">**(g)**</span> Assume that we use SGD with learning rate $\\eta=0.01$ to update the model parameters. What are the values of $W^2, b^2$ and $W^1, b^1$ after updating?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[4 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd086gw9Kotv"
   },
   "source": [
    "*Show your formula*\n",
    "\n",
    "To update W2 and b2, formula is applied:\n",
    "\n",
    "    W2 = W2 - (learning rate)(∂𝑙/∂W2)\n",
    "    b2 = b2 - (learning rate)(∂𝑙/∂b2)\n",
    "           \n",
    "To update W1 and b1, formula is applied:\n",
    "\n",
    "    W1 = W1 - (learning rate)(∂𝑙/∂W1)\n",
    "    b1 = b1 - (learning rate)(∂𝑙/∂b1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXI0_TEIKotv",
    "outputId": "223ff1df-af16-4174-cdc2-a270621e2a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 [[0.37314994 0.71813632 0.22141386 0.0391457  0.94663381]\n",
      " [0.86121315 0.82455649 0.39263771 0.8572277  0.40528532]\n",
      " [0.62679118 0.79372347 0.32519412 0.5609578  0.39898899]]\n",
      "b2 [[0.15861126]\n",
      " [0.41996357]\n",
      " [0.13059539]]\n",
      "W1 [[0.85757143 0.64176563 0.24066331]\n",
      " [0.20381796 0.32152008 0.52417057]\n",
      " [0.24345428 0.31014958 0.82308913]\n",
      " [0.93454786 0.06882313 0.74350092]\n",
      " [0.83293836 0.3035757  0.30921693]]\n",
      "b1 [[0.03650499]\n",
      " [0.49915336]\n",
      " [0.10805436]\n",
      " [0.61273292]\n",
      " [0.84692863]]\n"
     ]
    }
   ],
   "source": [
    "#Show your code\n",
    "\n",
    "# learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "W2 = W2 - (alpha*der_l_W2)\n",
    "b2 = b2 - (alpha*der_l_b2)\n",
    "\n",
    "W1 = W1 - (alpha*der_l_W1)\n",
    "b1 = b1 - (alpha*der_l_b1)\n",
    "\n",
    "print(\"W2\", W2)\n",
    "print(\"b2\", b2)\n",
    "print(\"W1\", W1)\n",
    "print(\"b1\", b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-guZ8FXTKotv"
   },
   "source": [
    "## <span style=\"color:#0b486b\">Part 2: Deep Neural Networks (DNN) </span>\n",
    "<div style=\"text-align: right\"><span style=\"color:red; font-weight:bold\">[Total marks for this part: 25 points]<span></div>\n",
    "\n",
    "The first part of this assignment is to demonstrate your basis knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the tutorials covered from weeks 1 to 4**. Going through these materials before attempting this assignment is highly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnZ28j19Kotv"
   },
   "source": [
    "In the first part of this assignment, you are going to work with the **FashionMNIST** dataset for *image recognition task*. It has the exact same format as MNIST (70,000 grayscale images of 28 × 28 pixels each with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse, and the problem is significantly more challenging than MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwtTsZDhKotv"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 2.1**</span>. Load the Fashion MNIST using Keras datasets\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "We first use keras incoporated in TensorFlow 2.x for loading the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dHoIW_FOKotw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XlsqhjWTKotw"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(31158145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccFfzQZwKotw"
   },
   "source": [
    "We first use keras datasets in TF 2.x to load Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gZ5vTMjOKotw"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full_img, y_train_full), (X_test_img, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dlZuVLyKotw"
   },
   "source": [
    "The shape of X_train_full_img is $(60000, 28, 28 )$ and that of X_test_img is $(10000, 28, 28)$. We next convert them to matrices of vectors and store in X_train_full and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvkhDRivKotw",
    "outputId": "755af21b-2143-41f1-e058-90147e667f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "num_train = X_train_full_img.shape[0]\n",
    "num_test = X_test_img.shape[0]\n",
    "#Get X_train_full and X_test\n",
    "\n",
    "print(num_train)\n",
    "print(num_test)\n",
    "\n",
    "X_train_full = X_train_full_img\n",
    "X_test = X_test_img\n",
    "\n",
    "#Shuffle X_train_full with the label\n",
    "train_val_idx = np.random.permutation(num_train)\n",
    "\n",
    "X_train_full = X_train_full[train_val_idx]\n",
    "y_train_full = y_train_full[train_val_idx]\n",
    "\n",
    "print(X_train_full.shape, y_train_full.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZDRZ6sFKotw"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 2.2**</span>. Preprocess the dataset and split into training, validation, and testing datasets\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "You need to write the code to address the following requirements:\n",
    "- Use $10 \\%$ of X_train_full for validation and the rest of X_train_full for training. This splits X_train_full and y_train_full into X_train, y_train ($90 \\%$) and X_valid, y_valid ($10 \\%$).\n",
    "- Finally, scale the pixels of X_train, X_valid, and X_test to $[0,1]$) (i.e., $X = X/255.0$).\n",
    "\n",
    "You have now the separate training, validation, and testing sets for training your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUq8gM_KKotw",
    "outputId": "7790199d-f05e-4fe9-93b0-bb9fb56a1705"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "N = X_train_full.shape[0]\n",
    "i = math.floor(0.9*N)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# reshape\n",
    "X_train_full, X_test = X_train_full.reshape(num_train, -1), X_test.reshape(num_test, -1)\n",
    "\n",
    "# split Train full set to train and valid set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.1)\n",
    "X_train, X_valid, X_test = X_train/255.0, X_valid/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZ9Oq6f7Kotw"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 2.3**</span>. Write code for the feed-forward neural net using TF 2.x\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdUBefTbKotw"
   },
   "source": [
    "We now develop a feed-forward neural network with the architecture $784 \\rightarrow 40(ReLU) \\rightarrow 30(ReLU) \\rightarrow 10(softmax)$. You can choose your own way to implement your network and an optimizer of interest. You should train model in $50$ epochs and evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzUmJBoXKotw",
    "outputId": "9abe9eb4-7472-4039-cdc7-b33d3975e0e9"
   },
   "outputs": [],
   "source": [
    "#Insert your code here and you can add more cells if necessary\n",
    "from tensorflow import keras\n",
    "\n",
    "class DNN:\n",
    "    def __init__(self, n_classes=10, optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                 batch_size=32, epochs=50, lr=0.01, activation_choice = 'relu', n1 = 40, n2 = 30):\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.lr = lr  # hyper-parameter corresponding to l2 loss\n",
    "\n",
    "        # custom parameter\n",
    "        self.act = activation_choice\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.test_acc = 0\n",
    "\n",
    "        # create a tensorflow dataset for train, test and valid sets\n",
    "        self.train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        self.valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "        self.test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "        # batching train, test and valid sets\n",
    "        self.train_set = self.train_set.batch(self.batch_size).prefetch(1)\n",
    "        self.valid_set = self.valid_set.batch(self.batch_size).prefetch(1)\n",
    "        self.test_set = self.test_set.batch(self.batch_size).prefetch(1)\n",
    "        tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "    def build(self):\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.n1, activation=self.act),\n",
    "            tf.keras.layers.Dense(self.n2, activation=self.act),\n",
    "            tf.keras.layers.Dense(self.n_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def compute_loss(self, X, y):  # X is data batch, y is label batch\n",
    "        pred_probs = self.model(X)\n",
    "        l1 = tf.keras.losses.sparse_categorical_crossentropy(y, pred_probs)  # Cross entropy loss\n",
    "        l2 = tf.add_n([tf.nn.l2_loss(w) for w in self.model.trainable_weights])\n",
    "        l2 = tf.expand_dims(l2, axis=-1)\n",
    "        return l1 + self.lr * l2\n",
    "\n",
    "\n",
    "    def compute_grads(self, X, y):\n",
    "        with tf.GradientTape() as g:  # use gradient tape to compute gradients\n",
    "            loss = self.compute_loss(X, y)\n",
    "        grads = g.gradient(loss, self.model.trainable_variables)  # compute gradients w.r.t. all trainable variables\n",
    "        return grads\n",
    "\n",
    "    def train_one_batch(self, X, y):  # train in one batch\n",
    "        grads = self.compute_grads(X, y)\n",
    "        # the gradients will be applied according to optimizer for example SGD, Adam, and etc.\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "    def evaluate(self, tf_dataset=None):\n",
    "        dataset_loss = tf.keras.metrics.Mean()\n",
    "        dataset_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        for X, y in tf_dataset:\n",
    "            loss = self.compute_loss(X, y)\n",
    "            dataset_loss.update_state(loss)\n",
    "            dataset_accuracy.update_state(y, self.model(X, training=False))\n",
    "        return dataset_loss.result(), dataset_accuracy.result()\n",
    "\n",
    "    def train(self):\n",
    "        print(\"===================================================================\")\n",
    "        print(\"parameters of \", self.n1, self.n2, self.act,self.optimizer,self.lr)\n",
    "        for epoch in range(self.epochs):\n",
    "            for X, y in self.train_set:  # use batch_index if you want to display something in iterations\n",
    "                self.train_one_batch(X, y)\n",
    "            train_loss, train_acc = self.evaluate(self.train_set)\n",
    "            valid_loss, valid_acc = self.evaluate(self.valid_set)\n",
    "            print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(\n",
    "                epoch + 1, train_acc, train_loss, valid_acc, valid_loss))\n",
    "\n",
    "    def test(self):\n",
    "        test_loss, test_acc = self.evaluate(self.test_set)\n",
    "        print('test acc={:.4f}, test loss={:.4f} '.format(test_acc, test_loss))\n",
    "        self.test_acc = test_acc\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "dnn = DNN(optimizer=opt, epochs=50, batch_size=64, lr=0.01, activation_choice = 'relu', n1 = 40, n2 = 30)\n",
    "dnn.build()\n",
    "dnn.train()\n",
    "dnn.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rm520QaKKotx"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 2.4**</span>. Tuning hyper-parameters with grid search\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "Assume that you need to tune the number of neurons on the first and second hidden layers $n_1 \\in \\{20, 40\\}$, $n_2 \\in \\{20, 40\\}$  and the used activation function  $act \\in \\{sigmoid, tanh, relu\\}$. The network has the architecture pattern $784 \\rightarrow n_1 (act) \\rightarrow n_2(act) \\rightarrow 10(softmax)$ where $n_1, n_2$, and $act$ are in their grides. Write the code to tune the hyper-parameters $n_1, n_2$, and $act$. Note that you can freely choose the optimizer and learning rate of interest for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sp5RyJ5KKotx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "\n",
    "# The code with comment are used to figure out the best optimiser and the learning rate.\n",
    "# For saving time of teaching team to run and test the codes, \n",
    "# optimiser and learning rate are preset to Adam and 0.001 respectively \n",
    "\n",
    "# lst_opts = [tf.keras.optimizers.Adam(), tf.keras.optimizers.RMSprop(), tf.keras.optimizers.SGD(momentum=0.2)]\n",
    "# lst_learning_rates = [0.1, 0.01, 0.001]\n",
    "# opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "n1 = [20, 40]\n",
    "n2 = [20, 40]\n",
    "activation_choices = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "\n",
    "comb = ['', 0,0]\n",
    "highest_acc = 0.0\n",
    "\n",
    "# lr = 0.01\n",
    "# for p in lst_opts:\n",
    "#     for q in lst_learning_rates:\n",
    "#         for x in n1:\n",
    "#             for y in n2:\n",
    "#                 for z in activation_choices:\n",
    "#                     print(\"Current best parameters = \", comb)\n",
    "#                     p.learning_rate = q\n",
    "#                     dnn = DNN(epochs=5, activation_choice = z, n1 = x, n2 = y, optimizer=p, lr = q)\n",
    "#                     dnn.build()\n",
    "#                     dnn.train()\n",
    "#                     dnn.test()\n",
    "#                     if highest_acc <= dnn.test_acc():\n",
    "#                         highest_acc = dnn.test_acc\n",
    "#                         comb = [p,q,z,x,y]\n",
    "\n",
    "# print(comb)\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "for x in n1:\n",
    "    for y in n2:\n",
    "        for z in activation_choices:\n",
    "            print(\"Current highest comb with the accuracy: \", comb, highest_acc)\n",
    "            dnn = DNN(epochs=20, activation_choice = z, n1 = x, n2 = y, optimizer=opt, lr = 0.001)\n",
    "            dnn.build()\n",
    "            dnn.train()\n",
    "            dnn.test()\n",
    "            if highest_acc <= dnn.test_acc:\n",
    "                highest_acc = dnn.test_acc\n",
    "                comb = [z,x,y]\n",
    "\n",
    "print(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uYxJze1Kotx"
   },
   "source": [
    "####  <span style=\"color:red\">**Question 2.5**</span>. Experimenting with **sharpness-aware minimization** technique\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n",
    "Sharpness-aware minimization (SAM) (i.e., [link for main paper](https://openreview.net/pdf?id=6Tm1mposlrM) from Google Deepmind) is a simple yet but efficient technique to improve the generalization ability of deep learning models on unseen data examples. In your research or your work, you might potentially use this idea. Your task is to read the paper and implement *Sharpness-aware minimization (SAM)*. Finally, you need to apply SAM to the best architecture found in **Question 2.4**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SSgSGuFKotx"
   },
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "class SAMOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, base_optimizer, rho=0.05, name=\"SAMOptimizer\", **kwargs):\n",
    "        super(SAMOptimizer, self).__init__(name, **kwargs)\n",
    "        self.base_optimizer = base_optimizer\n",
    "        self.rho = rho\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"theta_old\")\n",
    "\n",
    "    def _resource_apply(self, grad, var, indices=None):\n",
    "        base_op = self.base_optimizer\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        theta_old = self.get_slot(var, \"theta_old\")\n",
    "\n",
    "        # Compute the sharpness-aware update\n",
    "        grad_norm = tf.norm(grad)\n",
    "        epsilon = tf.constant(1e-12, dtype=grad_norm.dtype)\n",
    "        coeff = self.rho / (grad_norm + epsilon)\n",
    "        delta_theta = coeff * grad\n",
    "\n",
    "        # Apply the sharpness-aware update to the variable\n",
    "        var_t = var - delta_theta\n",
    "\n",
    "        with tf.control_dependencies([base_op.apply_gradients([(var_t - var, var)])]):\n",
    "            # Store the current weights for the next iteration\n",
    "            theta_old.assign(var_t)\n",
    "\n",
    "        return tf.group(*[var.assign(var_t)])\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        return self._resource_apply(grad, var)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices=None):\n",
    "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")\n",
    "        \n",
    "        \n",
    "# Usage:\n",
    "base_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# dnn = DNN(optimizer=base_optimizer, epochs=5, batch_size=64, lr=0.01, activation_choice = 'tanh', n1 = 40, n2 = 20)\n",
    "# dnn.build()\n",
    "# dnn.train()\n",
    "# dnn.test()\n",
    "\n",
    "opt = SAMOptimizer(base_optimizer, rho=0.05)\n",
    "\n",
    "dnn = DNN(optimizer=opt, epochs=20, batch_size=64, lr=0.01, activation_choice = 'tanh', n1 = 40, n2 = 20)\n",
    "dnn.build()\n",
    "dnn.train()\n",
    "dnn.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du0bk3a4Kotx"
   },
   "source": [
    "## <span style=\"color:#0b486b\">Part 3: Convolutional Neural Networks and Image Classification</span>\n",
    "\n",
    "**<div style=\"text-align: right\"><span style=\"color:red\">[Total marks for this part: 40 points]</span></div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdIRKYucKotx"
   },
   "source": [
    "**This part of the asssignment is designed to assess your knowledge and coding skill with Tensorflow as well as hands-on experience with training Convolutional Neural Network (CNN).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyxplyPLKotx"
   },
   "source": [
    "**The dataset used for this part is a specific dataset for this unit consisting of approximately $10,000$ images of $20$ classes, each of which has approximately 500 images. You can download the dataset at [download here](https://drive.google.com/file/d/1eURMjyUROowKeh5hKJPpZCLg7ne625fF/view?usp=sharing) and then decompress to the folder `datasets\\FIT5215_Dataset` in your assignment folder.**\n",
    "\n",
    "**Your task is to build a CNN model using *TF 2.x* to classify the images. You're provided with the module <span style=\"color:red\">models.py</span>, which you can find in the assignment folder, with some of the following classes:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gd4mE_75Kotx"
   },
   "source": [
    "1. `DatasetManager`: Support with loading and spliting the dataset into the train-val-test sets. It also supports generating next batches for training. `DatasetManager` will be passed to CNN model for training and testing.\n",
    "2. `DefaultModel`: A base class for the CNN model.\n",
    "3. `YourModel`: The class you'll need to implement for building your CNN model. It inherits some useful attributes and functions from the base class `DefaultModel`\n",
    "4. Note that you can freely modify the `models.py` file for your purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoidxGH6Kotx"
   },
   "source": [
    "Firstly, we need to run the following cells to load and preprocess the FIT5215 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6izEtlSKotx"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV_MJko4Kotx"
   },
   "source": [
    "Install the package `imutils` if you have not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ypc0v0qjKoty"
   },
   "outputs": [],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pEZ3MCAKoty"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import models\n",
    "from models import SimplePreprocessor, DatasetManager, DefaultModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fTs_lh8Koty"
   },
   "outputs": [],
   "source": [
    "def create_label_folder_dict(adir):\n",
    "    sub_folders= [folder for folder in os.listdir(adir)\n",
    "                  if os.path.isdir(os.path.join(adir, folder))]\n",
    "    label_folder_dict= dict()\n",
    "    for folder in sub_folders:\n",
    "        item= {folder: os.path.abspath(os.path.join(adir, folder))}\n",
    "        label_folder_dict.update(item)\n",
    "    return label_folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5Z0h90yKoty"
   },
   "outputs": [],
   "source": [
    "label_folder_dict= create_label_folder_dict(\"./datasets/FIT5215_Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kulJ17yMKoty"
   },
   "source": [
    "The below code helps to create a data manager that contains all relevant methods used to manage and process the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDJjtQoRKoty"
   },
   "outputs": [],
   "source": [
    "sp = SimplePreprocessor(width=32, height=32)\n",
    "data_manager = DatasetManager([sp])\n",
    "data_manager.load(label_folder_dict, verbose=100)\n",
    "data_manager.process_data_label()\n",
    "data_manager.train_valid_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEdgpuFsKoty"
   },
   "source": [
    "Note that the object `data_manager` has the attributes relating to *the training, validation, and testing sets* as shown belows. You can use them in training your developped models in the sequel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x1Vsv-bKoty"
   },
   "outputs": [],
   "source": [
    "print(data_manager.X_train.shape, data_manager.y_train.shape)\n",
    "print(data_manager.X_valid.shape, data_manager.y_valid.shape)\n",
    "print(data_manager.X_test.shape, data_manager.y_test.shape)\n",
    "print(data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JTteC4oKoty"
   },
   "source": [
    "We now run the **default model** built in the **models.py** file which serves as a basic baseline to start the investigation. Follow the following steps to realize how to run a model and know the built-in methods associated to a model developped in the DefaultModel class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seCR3HxHKoty"
   },
   "source": [
    "We first initialize a default model from the DefaultModel class. Basically, we can define the relevant parameters of training a model including `num_classes`, `optimizer`, `learning_rate`, `batch_size`, and `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1T0VjAwKoty"
   },
   "outputs": [],
   "source": [
    "network1 = DefaultModel(name='network1',\n",
    "                       num_classes=len(data_manager.classes),\n",
    "                       optimizer='sgd',\n",
    "                       batch_size= 128,\n",
    "                       num_epochs = 20,\n",
    "                       learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VujmIwwYKoty"
   },
   "source": [
    "The method `build_cnn()` assists us in building your convolutional neural network. You can view the code (in the **models.py** file) of the model behind a default model to realize how simple it is. Additionally, the method `summary()` shows the architecture of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4P3BME_Kotz"
   },
   "outputs": [],
   "source": [
    "network1.build_cnn()\n",
    "network1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmI8yo3CKotz"
   },
   "source": [
    "To train a model regarding to the datasets stored in `data_manager`, you can invoke the method `fit()` for which you can specify the batch size and number of epochs for your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSgyngrNKotz"
   },
   "outputs": [],
   "source": [
    "network1.fit(data_manager, batch_size = 64, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbOxl7UKotz"
   },
   "source": [
    "Here you can compute the accuracy of your trained model with respect to a separate testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFcAYxYUKotz"
   },
   "outputs": [],
   "source": [
    "network1.compute_accuracy(data_manager.X_test, data_manager.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAzRzLMVKotz"
   },
   "source": [
    "Below shows how you can inspect the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylTs3aBzKotz"
   },
   "outputs": [],
   "source": [
    "network1.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA4tCe1eKotz"
   },
   "source": [
    "You can use the method `predict()` to predict labels for data examples in a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn-8gZEvKotz"
   },
   "outputs": [],
   "source": [
    "network1.predict(data_manager.X_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wmfPMK3Kotz"
   },
   "source": [
    "Finally, the method `plot_prediction()` visualizes the predictions for a test set in which several images are chosen to show the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZQ0T40wKotz"
   },
   "outputs": [],
   "source": [
    "network1.plot_prediction(data_manager.X_test, data_manager.y_test, data_manager.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye2gosfvKot0"
   },
   "source": [
    "**For questions 3.1 to 3.7, you'll need to write your own model in a way that makes it easy for you to experiment with different architectures and parameters. The goal is to be able to pass the parameters to initialize a new instance of `YourModel` to build different network architectures with different parameters. Below are descriptions of some parameters for `YourModel`:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJDlGXfFKot0"
   },
   "source": [
    "1. `Block architecture`: Each block has the pattern `[conv, batch norm, activation, conv, batch norm, activation, mean pool]`. All convolutional layers have filter size $(3, 3)$, strides $(1, 1)$ and 'SAME' padding, and all mean pool layers have strides $(2, 2)$ and 'SAME' padding. The network will consists of a few blocks before applying a `global average pooling (GAP)` layer to obtain vectors and then a dense layer to output the logits for the softmax layer.\n",
    "\n",
    "When designing a block, there must have some instance variables as follows\n",
    "\n",
    "2. `num_channels`: the number of channels used in a block, which will be applied to two Convs in the block.\n",
    "\n",
    "3. `mean_pool (True, False)`: the mean pool is used not. If `mean_pool = True`, it is used to downsample the input by two.\n",
    "\n",
    "4. `batch_norm (True, False)`: the batch normalization function is used or not. Setting `batch_norm` to `False` means not using batch normalization.\n",
    "\n",
    "5. The `skip connection (True, False)` is added to the output of the second `batch norm`. Additionally, your class has a boolean property (i.e., instance variable) named `use_skip`. If `use_skip=True`, the skip connectnion is enable. Otherwise, if `use_skip=False`, the skip connectnion is disable.\n",
    "\n",
    "Below is the architecture of one block:\n",
    "\n",
    "<img src=\"Figures/OneBlock.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "Below is the architecture of the entire deep net with `two blocks`:\n",
    "\n",
    "<img src=\"Figures/NetworkArchitecture.png\" width=\"1200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bMl9HywKot0"
   },
   "source": [
    "The above network has two blocks with the numbers of channels are 16 and 32 respectively. We apply a global average pooling (GAP) layer to flattern the output of the last block, followed by an output layer for prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vL6aWcAxKot0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bjpost3iKot0"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(31158145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgL_blVdKot0"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.1**</span> **Write the code of the `YourModel` class here. Note that this class will inherit from the `DefaultModel` class. You'll only need to re-write the code for the `build_cnn` method in the `YourModel` class from the cell below. Note that the `YourModel` class   is inherited from the `DefaultModel` class.**\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[6 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "class YourModel(DefaultModel):\n",
    "    def __init__(self, name='network1', width = 32, height = 32, depth = 3, num_classes = 20, is_augmentation = False, \n",
    "                 activation_func = 'relu', optimizer='adam', batch_size=32, num_epochs= 20, learning_rate=0.001,\n",
    "                 verbose= True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_classes, is_augmentation,\n",
    "                                        activation_func, optimizer, batch_size, num_epochs,\n",
    "                                        learning_rate, verbose)\n",
    "        \n",
    "        # initialisation for paramters of the class\n",
    "        self.num_classes = num_classes\n",
    "        self.activation_func = activation_func\n",
    "        self.is_augmentation = False\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose= verbose\n",
    "    \n",
    "    \n",
    "    # cnn layer which build a basic layer of CNN blocks by blocks\n",
    "    def cnn_layer(self):\n",
    "        x = self.input_layer\n",
    "        for l in range(self.num_blocks):\n",
    "            input_org = x\n",
    "            self.num_channels *= 2\n",
    "            s = self.num_channels\n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)   \n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            \n",
    "            # Code for necessary action when used_skip\n",
    "            if self.used_skip:\n",
    "                desired_channels = s\n",
    "                channels_to_add = desired_channels - input_org.shape[-1]\n",
    "\n",
    "                # Check if channels need to be added\n",
    "                if channels_to_add > 0:\n",
    "                    # Create a tensor of zeros with the desired shape\n",
    "                    zero_channels = tf.zeros((tf.shape(input_org)[0], tf.shape(input_org)[1], tf.shape(input_org)[2], channels_to_add))\n",
    "\n",
    "                    # Concatenate the zero-initialized channels to the input tensor\n",
    "                    padded_tensor = tf.keras.layers.Concatenate(axis=-1)([input_org, zero_channels])\n",
    "\n",
    "                else:\n",
    "                    # No padding needed, keep the input tensor as is\n",
    "                    padded_tensor = input_org\n",
    "                \n",
    "                x = keras.layers.add([x, padded_tensor])\n",
    "\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)\n",
    "            if self.mean_pool:\n",
    "                # mean pooling\n",
    "                x = layers.AveragePooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        return x\n",
    "        \n",
    "         \n",
    "    def cnn(self, strides=1, num_channels = 16, num_blocks = 16, mean_pool=True, batch_norm=True, used_skip=True, \n",
    "             num_classes=20, batch_size = 32):\n",
    "        # initialisation for parameters\n",
    "        input_data = data_manager.next_batch(batch_size = batch_size)\n",
    "        self.strides = strides \n",
    "        self.num_channels = num_channels\n",
    "        self.mean_pool = mean_pool\n",
    "        self.batch_norm = batch_norm\n",
    "        self.used_skip = used_skip \n",
    "        self.input_data = input_data[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.used_skip = used_skip\n",
    "        self.num_blocks = num_blocks\n",
    "        # set up the input layer \n",
    "        self.width = self.input_data.shape[1]\n",
    "        self.height = self.input_data.shape[2]\n",
    "        self.depth = self.input_data.shape[3]\n",
    "        \n",
    "        self.input_layer = layers.Input(shape = (self.width,self.height,self.depth))\n",
    "        \n",
    "        # cnn layer \n",
    "        x1 = self.cnn_layer()\n",
    "        return x1\n",
    "        \n",
    "        \n",
    "    def build_cnn(self, num_channels, num_blocks, batch_norm, use_skip, mean_pool, batch_size):\n",
    "        #Insert your code here\n",
    "        x1 = self.cnn(num_blocks = num_blocks, num_channels = num_channels, mean_pool=mean_pool, \n",
    "                                batch_norm=batch_norm, used_skip=use_skip, batch_size = batch_size)\n",
    "            \n",
    "        # last layer of whole cnn model which flat and dense\n",
    "        x1 = layers.GlobalAvgPool2D()(x1)\n",
    "        y1 = layers.Flatten()(x1)\n",
    "        output = layers.Dense(self.num_classes, activation='softmax')(y1)\n",
    "        # Instantiate model\n",
    "        self.model = tf.keras.models.Model(inputs=self.input_layer, outputs=output)\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbQ1h4kJKot0"
   },
   "source": [
    "Now run your model with a specific configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CN1zjdxkKot1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your run here\n",
    "my_cnn_model = YourModel(learning_rate = 0.001)\n",
    "\n",
    "my_cnn_model.build_cnn(num_channels = 16, num_blocks = 2, mean_pool=True, batch_norm=True, \n",
    "                     use_skip=True, batch_size = 16)\n",
    "my_cnn_model.summary()\n",
    "my_cnn_model.fit(data_manager, batch_size = 16, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk30D5BKKot1"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.2**</span> **Now, let us tune the number of blocks $num\\_blocks \\in \\{3,4\\}$, $use\\_skip \\in \\{True, False\\}$, $mean\\_pool \\in \\{True, False\\}$, and $learning\\_rate \\in \\{0.001, 0.0001\\}$. Write your code for this tuning and report the result of the best model on the testing set. Note that you need to show your code for tuning and evaluating on the test set to earn the full marks. During tuning, you can set the instance variable `verbose` of your model to `False` for not showing the training details of each epoch.**\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59SkHASuKot1"
   },
   "source": [
    "#*Report the best parameters and the testing accuracy here*\n",
    "\n",
    "Best parameters: num_blocks = 4, use_skip = True, mean_pool = True, learning_rate = 0.0001\n",
    "\n",
    "Other parameters: batch_size = 16, num_epochs = 20\n",
    "\n",
    "    Train Accuracy: 0.9801\n",
    "    Valid Accuracy: 0.4153\n",
    "    Test Accuracy : 0.4375\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NTHhRrQKot1"
   },
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "num_blocks = [3,4]\n",
    "use_skip = [True, False]\n",
    "mean_pool = [True, False]\n",
    "learning_rate = [0.001, 0.0001]\n",
    "# 4 t t 0.0001\n",
    "\n",
    "# For loop to find the best parameter from the combination. \n",
    "# To save the running time, we will only call and build the model with the best performance   \n",
    "# for w in num_blocks:\n",
    "#     for x in use_skip:\n",
    "#         for y in mean_pool:\n",
    "#             for z in learning_rate:\n",
    "#                 print(\"current combintation: \", w,x,y,z)\n",
    "#                 my_network = YourModel(learning_rate=z, verbose= False)\n",
    "#                 my_network.build_cnn(num_channels = 16, num_blocks = w, mean_pool=y, batch_norm=True, \n",
    "#                                      use_skip=x, batch_size = 16)\n",
    "#                 my_network.fit(data_manager, batch_size = 16, num_epochs=20)\n",
    "#                 my_network.compute_accuracy(data_manager.X_test, data_manager.y_test, batch_size = 16)\n",
    "\n",
    "\n",
    "my_cnn_model = YourModel(learning_rate = 0.0001)\n",
    "\n",
    "my_cnn_model.build_cnn(num_channels = 16, num_blocks = 4, mean_pool=True, batch_norm=True, \n",
    "                     use_skip=True, batch_size = 16)\n",
    "\n",
    "my_cnn_model.fit(data_manager, batch_size = 16, num_epochs=20)\n",
    "my_cnn_model.compute_accuracy(data_manager.X_test, data_manager.y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsEExlAHKot1"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.3**</span> **We now try to apply data augmentation to improve the performance. Extend the code of the class `YourModel` so that if the attribute `is_augmentation` is set to `True`, we apply the data augmentation. Also you need to incorporate early stopping to your training process. Specifically, you early stop the training if the valid accuracy cannot increase in three consecutive epochs.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqbFFOebKot1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cQFPeVTKot1"
   },
   "source": [
    "Wtire your code in the cell below. Hint that you can rewrite the code of the `fit` method to apply the data augmentation. In addition, you can copy the code of `build_cnn` method above to reuse here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRQ4OoA8Kot1"
   },
   "outputs": [],
   "source": [
    "class YourModel(DefaultModel):\n",
    "    def __init__(self, name='network1', width = 32, height = 32, depth = 3, num_classes = 20, is_augmentation = False, \n",
    "                 activation_func = 'relu', optimizer='adam', batch_size=32, num_epochs= 20, learning_rate=0.001,\n",
    "                 verbose= True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_classes, is_augmentation,\n",
    "                                        activation_func, optimizer, batch_size, num_epochs,\n",
    "                                        learning_rate, verbose)\n",
    "        \n",
    "        # initialisation for paramters of the class\n",
    "        self.num_classes = num_classes\n",
    "        self.activation_func = activation_func\n",
    "        self.is_augmentation = is_augmentation\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose= verbose\n",
    "    \n",
    "    \n",
    "    # cnn layer which build a basic layer of CNN blocks by blocks\n",
    "    def cnn_layer(self):\n",
    "        x = self.input_layer\n",
    "        for l in range(self.num_blocks):\n",
    "            input_org = x\n",
    "            self.num_channels *= 2\n",
    "            s = self.num_channels\n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)   \n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            \n",
    "            # Code for necessary action when used_skip\n",
    "            if self.used_skip:\n",
    "                desired_channels = s\n",
    "                channels_to_add = desired_channels - input_org.shape[-1]\n",
    "\n",
    "                # Check if channels need to be added\n",
    "                if channels_to_add > 0:\n",
    "                    # Create a tensor of zeros with the desired shape\n",
    "                    zero_channels = tf.zeros((tf.shape(input_org)[0], tf.shape(input_org)[1], tf.shape(input_org)[2], channels_to_add))\n",
    "\n",
    "                    # Concatenate the zero-initialized channels to the input tensor\n",
    "                    padded_tensor = tf.keras.layers.Concatenate(axis=-1)([input_org, zero_channels])\n",
    "\n",
    "                else:\n",
    "                    # No padding needed, keep the input tensor as is\n",
    "                    padded_tensor = input_org\n",
    "                \n",
    "                x = keras.layers.add([x, padded_tensor])\n",
    "\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)\n",
    "            if self.mean_pool:\n",
    "                # mean pooling\n",
    "                x = layers.AveragePooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        return x\n",
    "        \n",
    "         \n",
    "    def cnn(self, strides=1, num_channels = 16, num_blocks = 16, mean_pool=True, batch_norm=True, used_skip=True, \n",
    "             num_classes=20, batch_size = 32):\n",
    "        # initialisation for parameters\n",
    "        input_data = data_manager.next_batch(batch_size = batch_size)\n",
    "        self.strides = strides \n",
    "        self.num_channels = num_channels\n",
    "        self.mean_pool = mean_pool\n",
    "        self.batch_norm = batch_norm\n",
    "        self.used_skip = used_skip \n",
    "        self.input_data = input_data[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.used_skip = used_skip\n",
    "        self.num_blocks = num_blocks\n",
    "        # set up the input layer \n",
    "        self.width = self.input_data.shape[1]\n",
    "        self.height = self.input_data.shape[2]\n",
    "        self.depth = self.input_data.shape[3]\n",
    "        \n",
    "        self.input_layer = layers.Input(shape = (self.width,self.height,self.depth))\n",
    "        \n",
    "        # cnn layer \n",
    "        x1 = self.cnn_layer()\n",
    "        return x1\n",
    "        \n",
    "        \n",
    "    def build_cnn(self, num_channels, num_blocks, batch_norm, use_skip, mean_pool, batch_size):\n",
    "        #Insert your code here\n",
    "        x1 = self.cnn(num_blocks = num_blocks, num_channels = num_channels, mean_pool=mean_pool, \n",
    "                                batch_norm=batch_norm, used_skip=use_skip, batch_size = batch_size)\n",
    "            \n",
    "        # last layer of whole cnn model which flat and dense\n",
    "        x1 = layers.GlobalAvgPool2D()(x1)\n",
    "        y1 = layers.Flatten()(x1)\n",
    "        output = layers.Dense(self.num_classes, activation='softmax')(y1)\n",
    "        # Instantiate model\n",
    "        self.model = tf.keras.models.Model(inputs=self.input_layer, outputs=output)\n",
    "\n",
    "        \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None):\n",
    "        #Insert your code here\n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # data augmentation\n",
    "        if self.is_augmentation:\n",
    "            # augmentate the data\n",
    "            datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
    "            datagen.fit(data_manager.X_train)\n",
    "            augmented_data = datagen.flow(data_manager.X_train, data_manager.y_train, batch_size=batch_size)\n",
    "            self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            # fit the augmentated data\n",
    "            self.history = self.model.fit(augmented_data, validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                          epochs = num_epochs, batch_size = batch_size, verbose= self.verbose, \n",
    "                                          callbacks = [early_stopping])\n",
    "            \n",
    "        else:\n",
    "            batch_size = self.batch_size if batch_size is None else batch_size\n",
    "            num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "            self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            self.history = self.model.fit(x = data_manager.X_train, y = data_manager.y_train, \n",
    "                                          validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                          epochs = num_epochs, batch_size = batch_size, verbose= self.verbose,\n",
    "                                          callbacks = [early_stopping])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AqiEtq1Kot1"
   },
   "source": [
    "Leverage your best model with the data augmentation and try to observe the difference in performance between using data augmentation and non-using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGUASpQNKot1"
   },
   "source": [
    "#*Write your answer and observation here*\n",
    "\n",
    "Parameters: num_blocks = 4, use_skip = True, mean_pool = True, learning_rate = 0.0001\n",
    "\n",
    "Other parameters: batch_size = 16, num_epochs = 20\n",
    "\n",
    "**Without data augmentation**\n",
    "    \n",
    "    Train Accuracy: 0.9801\n",
    "    Valid Accuracy: 0.4153\n",
    "    Test Accuracy : 0.4375\n",
    "    \n",
    "**With data augmentation**\n",
    "    \n",
    "    Train Accuracy: 0.7051\n",
    "    Valid accuracy: 0.5604\n",
    "    Test Accuracy : 0.5561\n",
    "    \n",
    "We can observe that higher Train accuracy occurs without using data augmentation but having lower Valid and Test Accuracy. This is because without data augmentation, model will brute force try to memorise the pattern which often called overfitting. To overcome the issue, data augmentation augmentate the pattern to avoid the overfitting behaviour which return higher valid and test accuracy but lower train accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "my_cnn_model = YourModel(learning_rate = 0.0001, is_augmentation = True)\n",
    "\n",
    "my_cnn_model.build_cnn(num_channels = 16, num_blocks = 4, mean_pool=True, batch_norm=True, \n",
    "                     use_skip=True, batch_size = 16)\n",
    "my_cnn_model.fit(data_manager, batch_size = 16, num_epochs=20)\n",
    "my_cnn_model.compute_accuracy(data_manager.X_test, data_manager.y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAZPjwjEKot2"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.4**</span> **Exploring Data Mixup Technique for Improving Generalization Ability.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>\n",
    "\n",
    "Data mixup is another super-simple technique used to boost the generalization ability of deep learning models. You need to incoroporate data mixup technique to the above deep learning model and experiment its performance. There are some papers and documents for data mixup as follows:\n",
    "- Main paper for data mixup [link for main paper](https://openreview.net/pdf?id=r1Ddp1-Rb) and a good article [article link](https://www.inference.vc/mixup-data-dependent-data-augmentation/).\n",
    "\n",
    "You need to extend your model developed above, train a model using data mixup, and write your observations and comments about the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-SnayxrKot2"
   },
   "source": [
    "#*Write your answer and observation here*\n",
    "\n",
    "Parameters: num_blocks = 4, use_skip = True, mean_pool = True, learning_rate = 0.0001\n",
    "\n",
    "Other parameters: batch_size = 16, num_epochs = 20, data_augmentation = True\n",
    "\n",
    "**Without data mixup**\n",
    "    \n",
    "    Train Accuracy: 0.7051\n",
    "    Valid accuracy: 0.5604\n",
    "    Test Accuracy : 0.5561\n",
    "    \n",
    "**With data mixup**\n",
    "\n",
    "    Train Accuracy: 0.7271\n",
    "    Valid accuracy: 0.6017\n",
    "    Test Accuracy : 0.6133\n",
    "    \n",
    "With data mixup, the model is able to produce better training, valid and testing accuracy. This is because we add in more mixed data to train, generalise and reduce noise of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJXVdBzhKot2"
   },
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "class YourModel(DefaultModel):\n",
    "    def __init__(self, name='network1', width = 32, height = 32, depth = 3, num_classes = 20, is_augmentation = False, \n",
    "                 activation_func = 'relu', optimizer='adam', batch_size=32, num_epochs= 20, learning_rate=0.001,\n",
    "                 verbose= True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_classes, is_augmentation,\n",
    "                                        activation_func, optimizer, batch_size, num_epochs,\n",
    "                                        learning_rate, verbose)\n",
    "        \n",
    "        # initialisation for paramters of the class\n",
    "        self.num_classes = num_classes\n",
    "        self.activation_func = activation_func\n",
    "        self.is_augmentation = is_augmentation\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose= verbose\n",
    "    \n",
    "    \n",
    "    # cnn layer which build a basic layer of CNN blocks by blocks\n",
    "    def cnn_layer(self):\n",
    "        x = self.input_layer\n",
    "        for l in range(self.num_blocks):\n",
    "            input_org = x\n",
    "            self.num_channels *= 2\n",
    "            s = self.num_channels\n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)   \n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            \n",
    "            # Code for necessary action when used_skip\n",
    "            if self.used_skip:\n",
    "                desired_channels = s\n",
    "                channels_to_add = desired_channels - input_org.shape[-1]\n",
    "\n",
    "                # Check if channels need to be added\n",
    "                if channels_to_add > 0:\n",
    "                    # Create a tensor of zeros with the desired shape\n",
    "                    zero_channels = tf.zeros((tf.shape(input_org)[0], tf.shape(input_org)[1], tf.shape(input_org)[2], channels_to_add))\n",
    "\n",
    "                    # Concatenate the zero-initialized channels to the input tensor\n",
    "                    padded_tensor = tf.keras.layers.Concatenate(axis=-1)([input_org, zero_channels])\n",
    "\n",
    "                else:\n",
    "                    # No padding needed, keep the input tensor as is\n",
    "                    padded_tensor = input_org\n",
    "                \n",
    "                x = keras.layers.add([x, padded_tensor])\n",
    "\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)\n",
    "            if self.mean_pool:\n",
    "                # mean pooling\n",
    "                x = layers.AveragePooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        return x\n",
    "        \n",
    "         \n",
    "    def cnn(self, strides=1, num_channels = 16, num_blocks = 16, mean_pool=True, batch_norm=True, used_skip=True, \n",
    "             num_classes=20, batch_size = 32):\n",
    "        # initialisation for parameters\n",
    "        input_data = data_manager.next_batch(batch_size = batch_size)\n",
    "        self.strides = strides \n",
    "        self.num_channels = num_channels\n",
    "        self.mean_pool = mean_pool\n",
    "        self.batch_norm = batch_norm\n",
    "        self.used_skip = used_skip \n",
    "        self.input_data = input_data[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.used_skip = used_skip\n",
    "        self.num_blocks = num_blocks\n",
    "        # set up the input layer \n",
    "        self.width = self.input_data.shape[1]\n",
    "        self.height = self.input_data.shape[2]\n",
    "        self.depth = self.input_data.shape[3]\n",
    "        \n",
    "        self.input_layer = layers.Input(shape = (self.width,self.height,self.depth))\n",
    "        \n",
    "        # cnn layer \n",
    "        x1 = self.cnn_layer()\n",
    "        return x1\n",
    "        \n",
    "        \n",
    "    def build_cnn(self, num_channels, num_blocks, batch_norm, use_skip, mean_pool, batch_size):\n",
    "        #Insert your code here\n",
    "        x1 = self.cnn(num_blocks = num_blocks, num_channels = num_channels, mean_pool=mean_pool, \n",
    "                                batch_norm=batch_norm, used_skip=use_skip, batch_size = batch_size)\n",
    "            \n",
    "        # last layer of whole cnn model which flat and dense\n",
    "        x1 = layers.GlobalAvgPool2D()(x1)\n",
    "        y1 = layers.Flatten()(x1)\n",
    "        output = layers.Dense(self.num_classes, activation='softmax')(y1)\n",
    "        # Instantiate model\n",
    "        self.model = tf.keras.models.Model(inputs=self.input_layer, outputs=output)\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # mix up function which follow the formula of mixed_xy = (lambda * xy) + ((1 - lambda) * xy)\n",
    "    def mixup(self, x1, y1, x2, y2, alpha=0.2):\n",
    "        y1 = tf.one_hot(y1, 20)\n",
    "        y2 = tf.one_hot(y2, 20)\n",
    "        beta = np.random.beta(alpha, alpha)\n",
    "        mixed_x = (beta * x1) + ((1 - beta) * x2)\n",
    "        mixed_y = (beta * y1) + ((1 - beta) * y2)\n",
    "        return mixed_x, mixed_y\n",
    "    \n",
    "    \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None, is_augmentation = True):\n",
    "        #Insert your code here\n",
    "        self.is_augmentation = is_augmentation\n",
    "        \n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # data mix up \n",
    "        mixed_X = []\n",
    "        mixed_y = []\n",
    "        data_size = data_manager.X_train.shape[0]\n",
    "        \n",
    "        # loop through the dataset and mix two consecutives data\n",
    "        for i in range(0,data_size,2):\n",
    "            mixed_x_element, mixed_y_element = self.mixup(data_manager.X_train[i], data_manager.y_train[i], data_manager.X_train[i+1], data_manager.y_train[i+1], alpha = 0.2)\n",
    "            mixed_X.append(mixed_x_element)\n",
    "            mixed_y.append(mixed_y_element)\n",
    "        \n",
    "        # convert normal array to np array\n",
    "        mixed_X = np.array(mixed_X)\n",
    "        mixed_y = np.array(mixed_y)\n",
    "        # covnert one hot vector back to normal vector for y label\n",
    "        mixed_y = np.argmax(mixed_y, axis=1)\n",
    "        # concatenate original train set with mixup set\n",
    "        final_x = np.concatenate((data_manager.X_train, mixed_X)) \n",
    "        final_y = np.concatenate((data_manager.y_train, mixed_y))\n",
    "        \n",
    "        # data augmentation\n",
    "        if self.is_augmentation:\n",
    "            datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
    "            datagen.fit(final_x)\n",
    "            augmented_data = datagen.flow(final_x, final_y, batch_size=batch_size)\n",
    "            self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            self.history = self.model.fit(augmented_data, validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                          epochs = num_epochs, batch_size = batch_size, verbose= self.verbose, \n",
    "                                          callbacks = [early_stopping])\n",
    "            \n",
    "        else:\n",
    "            batch_size = self.batch_size if batch_size is None else batch_size\n",
    "            num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "            self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "            self.history = self.model.fit(x = final_x, y = final_y, \n",
    "                                          validation_data = (data_manager.X_valid, data_manager.y_valid), \n",
    "                                          epochs = num_epochs, batch_size = batch_size, verbose= self.verbose,\n",
    "                                          callbacks = [early_stopping])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cnn_model = YourModel(learning_rate = 0.001, is_augmentation = True)\n",
    "\n",
    "my_cnn_model.build_cnn(num_channels = 16, num_blocks = 4, mean_pool=True, batch_norm=True, \n",
    "                     use_skip=True, batch_size = 16)\n",
    "\n",
    "\n",
    "my_cnn_model.fit(data_manager, batch_size = 16, num_epochs=20, is_augmentation = True)\n",
    "my_cnn_model.compute_accuracy(data_manager.X_test, data_manager.y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XALL-QnhKot2"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.5**</span> Implement the **one-versus-all (OVA)** loss. The details are as follows:\n",
    "- You need to apply `the sigmoid activation function` to logits $h = [h_1, h_2,...,h_M]$ instead of `the softmax activation` function as usual to obtain $p = [p_1, p_2,...,p_M]$, meaning that $p_i = sigmoid(h_i), i=1,...,M$. Note that $M$ is the number of classes.\n",
    "- Given a data example $x$ with the ground-truth label $y$, the idea is to maximize the likelihood $p_y$ and to minimize the likelihoods $p_i, i \\neq y$. Therefore, the objective function is to find the model parameters to\n",
    "  - $\\max\\left\\{ \\log p_{y}+\\sum_{i\\neq y}\\log(1-p_{i})\\right\\}$ or equivalently $\\min\\left\\{ -\\log p_{y}-\\sum_{i\\neq y}\\log(1-p_{i})\\right\\}$.\n",
    "  - For example, if $M=3$ and $y=2$, you need to minimize $\\min\\left\\{ -\\log(1-p_{1})-\\log p_{2}-\\log(1-p_{3})\\right\\}$.\n",
    "\n",
    "Compare the model trained with the OVA loss and the same model trained with the standard cross-entropy loss.\n",
    "\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[5 points]</span> </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: num_blocks = 4, use_skip = True, mean_pool = True, learning_rate = 0.0001\n",
    "\n",
    "Other parameters: batch_size = 16, num_epochs = 20, data_augmentation = True\n",
    "\n",
    "CE loss\n",
    "\n",
    "    Train Accuracy: 0.7271\n",
    "    Valid accuracy: 0.6017\n",
    "    Test Accuracy : 0.6133\n",
    "\n",
    "OVA loss\n",
    "\n",
    "    Train Accuracy: 0.8625\n",
    "    Valid accuracy: 0.6250\n",
    "    Test Accuracy : 0.6642\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "# function to compute OVA loss\n",
    "def ova_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    # loop through number of unique classees in our case is 20\n",
    "    for class_index in range(20):\n",
    "        # binary label\n",
    "        binary_labels = tf.cast(y_true == class_index, tf.float32)\n",
    "        # compute loss using formula\n",
    "        class_loss = -binary_labels * tf.math.log(y_pred[:, class_index]) - (1 - binary_labels) * tf.math.log(1 - y_pred[:, class_index])\n",
    "        loss += class_loss\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "class YourModel(DefaultModel):\n",
    "    def __init__(self, name='network1', width = 32, height = 32, depth = 3, num_classes = 20, is_augmentation = False, \n",
    "                 activation_func = 'relu', optimizer='adam', batch_size=32, num_epochs= 20, learning_rate=0.001,\n",
    "                 verbose= True):\n",
    "        super(YourModel, self).__init__(name, width, height, depth, num_classes, is_augmentation,\n",
    "                                        activation_func, optimizer, batch_size, num_epochs,\n",
    "                                        learning_rate, verbose)\n",
    "        \n",
    "        # initialisation for paramters of the class\n",
    "        self.num_classes = num_classes\n",
    "        self.activation_func = activation_func\n",
    "        self.is_augmentation = is_augmentation\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose= verbose\n",
    "    \n",
    "    \n",
    "    # cnn layer which build a basic layer of CNN blocks by blocks\n",
    "    def cnn_layer(self):\n",
    "        x = self.input_layer\n",
    "        for l in range(self.num_blocks):\n",
    "            input_org = x\n",
    "            self.num_channels *= 2\n",
    "            s = self.num_channels\n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)   \n",
    "            # conv 2d\n",
    "            x = (layers.Conv2D(self.num_channels, (3,3), strides = self.strides, padding='same'))(x)\n",
    "            # batch norm\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            \n",
    "            # Code for necessary action when used_skip\n",
    "            if self.used_skip:\n",
    "                desired_channels = s\n",
    "                channels_to_add = desired_channels - input_org.shape[-1]\n",
    "\n",
    "                # Check if channels need to be added\n",
    "                if channels_to_add > 0:\n",
    "                    # Create a tensor of zeros with the desired shape\n",
    "                    zero_channels = tf.zeros((tf.shape(input_org)[0], tf.shape(input_org)[1], tf.shape(input_org)[2], channels_to_add))\n",
    "\n",
    "                    # Concatenate the zero-initialized channels to the input tensor\n",
    "                    padded_tensor = tf.keras.layers.Concatenate(axis=-1)([input_org, zero_channels])\n",
    "\n",
    "                else:\n",
    "                    # No padding needed, keep the input tensor as is\n",
    "                    padded_tensor = input_org\n",
    "                \n",
    "                x = keras.layers.add([x, padded_tensor])\n",
    "\n",
    "            # activation\n",
    "            x = layers.Activation(self.activation_func)(x)\n",
    "            if self.mean_pool:\n",
    "                # mean pooling\n",
    "                x = layers.AveragePooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "        return x\n",
    "        \n",
    "         \n",
    "    def cnn(self, strides=1, num_channels = 16, num_blocks = 16, mean_pool=True, batch_norm=True, used_skip=True, \n",
    "             num_classes=20, batch_size = 32):\n",
    "        # initialisation for parameters\n",
    "        input_data = data_manager.next_batch(batch_size = batch_size)\n",
    "        self.strides = strides \n",
    "        self.num_channels = num_channels\n",
    "        self.mean_pool = mean_pool\n",
    "        self.batch_norm = batch_norm\n",
    "        self.used_skip = used_skip \n",
    "        self.input_data = input_data[0]\n",
    "        self.num_classes = num_classes\n",
    "        self.used_skip = used_skip\n",
    "        self.num_blocks = num_blocks\n",
    "        # set up the input layer \n",
    "        self.width = self.input_data.shape[1]\n",
    "        self.height = self.input_data.shape[2]\n",
    "        self.depth = self.input_data.shape[3]\n",
    "        \n",
    "        self.input_layer = layers.Input(shape = (self.width,self.height,self.depth))\n",
    "        \n",
    "        # cnn layer \n",
    "        x1 = self.cnn_layer()\n",
    "        return x1\n",
    "        \n",
    "        \n",
    "    def build_cnn(self, num_channels, num_blocks, batch_norm, use_skip, mean_pool, batch_size):\n",
    "        #Insert your code here\n",
    "        x1 = self.cnn(num_blocks = num_blocks, num_channels = num_channels, mean_pool=mean_pool, \n",
    "                                batch_norm=batch_norm, used_skip=use_skip, batch_size = batch_size)\n",
    "            \n",
    "        # last layer of whole cnn model which flat and dense\n",
    "        x1 = layers.GlobalAvgPool2D()(x1)\n",
    "        y1 = layers.Flatten()(x1)\n",
    "        output = layers.Dense(self.num_classes, activation='sigmoid')(y1)\n",
    "        # Instantiate model\n",
    "        self.model = tf.keras.models.Model(inputs=self.input_layer, outputs=output)\n",
    "        self.model.compile(optimizer=self.optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # mix up function which follow the formula of mixed_xy = (lambda * xy) + ((1 - lambda) * xy)\n",
    "    def mixup(self, x1, y1, x2, y2, alpha=0.2):\n",
    "        y1 = tf.one_hot(y1, 20)\n",
    "        y2 = tf.one_hot(y2, 20)\n",
    "        beta = np.random.beta(alpha, alpha)\n",
    "        mixed_x = (beta * x1) + ((1 - beta) * x2)\n",
    "        mixed_y = (beta * y1) + ((1 - beta) * y2)\n",
    "        return mixed_x, mixed_y\n",
    "    \n",
    "    \n",
    "    def fit(self, data_manager, batch_size=None, num_epochs=None, is_augmentation = True, ova_loss=None):\n",
    "        #Insert your code here\n",
    "        self.is_augmentation = is_augmentation\n",
    "        \n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        num_epochs = self.num_epochs if num_epochs is None else num_epochs\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        # data mix up \n",
    "        mixed_X = []\n",
    "        mixed_y = []\n",
    "        data_size = data_manager.X_train.shape[0]\n",
    "        \n",
    "        # loop through the dataset and mix two consecutives data\n",
    "        for i in range(0,data_size,2):\n",
    "            mixed_x_element, mixed_y_element = self.mixup(data_manager.X_train[i], data_manager.y_train[i], data_manager.X_train[i+1], data_manager.y_train[i+1], alpha = 0.2)\n",
    "            mixed_X.append(mixed_x_element)\n",
    "            mixed_y.append(mixed_y_element)\n",
    "        \n",
    "        # convert normal array to np array\n",
    "        mixed_X = np.array(mixed_X)\n",
    "        mixed_y = np.array(mixed_y)\n",
    "        # covnert one hot vector back to normal vector for y label\n",
    "        # mixed_y = np.argmax(mixed_y, axis=1)\n",
    "        # concatenate original train set with mixup set\n",
    "        my_y = tf.one_hot(data_manager.y_train, 20)\n",
    "        final_x = np.concatenate((data_manager.X_train, mixed_X)) \n",
    "        final_y = np.concatenate((my_y, mixed_y))\n",
    "        my_y_valid = tf.one_hot(data_manager.y_valid, 20)\n",
    "        \n",
    "        \n",
    "        # data augmentation. To make the code more clean and visible, assume that the model now will always do data augmentation\n",
    "        datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
    "        datagen.fit(final_x)\n",
    "        augmented_data = datagen.flow(final_x, final_y, batch_size=batch_size)\n",
    "        self.history = self.model.fit(augmented_data,\n",
    "                                      validation_data = (data_manager.X_valid, my_y_valid), \n",
    "                                      epochs = num_epochs, batch_size = batch_size, verbose= self.verbose, \n",
    "                                      callbacks = [early_stopping])\n",
    "        \n",
    "        self.model.compile(optimizer=self.optimizer, loss=ova_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cnn_model = YourModel(learning_rate = 0.001, is_augmentation = True)\n",
    "\n",
    "my_cnn_model.build_cnn(num_channels = 16, num_blocks = 4, mean_pool=True, batch_norm=True, \n",
    "                     use_skip=True, batch_size = 16)\n",
    "\n",
    "my_cnn_model.fit(data_manager, batch_size = 16, num_epochs=20, is_augmentation = True, ova_loss = ova_loss)\n",
    "my_cnn_model.compute_accuracy(data_manager.X_test, data_manager.y_test, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfLDwIDRKot2"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.6**</span> **Attack your best obtained model with PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set. Write the code for the attacks and report the robust accuracies. Also choose a random set of 20 clean images in the testing set and visualize the original and attacked images.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[3 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mluU0mNKot2"
   },
   "outputs": [],
   "source": [
    "#Insert your code here. You can add more cells if necessary\n",
    "# Refers to code in FIT5057 S2 tutorial 6b\n",
    "def pgd_attack(model, input_image, input_label= None, \n",
    "              epsilon=0.3, \n",
    "              num_steps=20, \n",
    "              step_size=0.01, \n",
    "              clip_value_min=0., \n",
    "              clip_value_max=1.0, \n",
    "              soft_label=False,\n",
    "              from_logits= True): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        model: pretrained model \n",
    "        input_image: original (clean) input image (tensor)\n",
    "        input_label: original label (tensor, categorical representation)\n",
    "        epsilon: perturbation boundary \n",
    "        num_steps: number of attack steps \n",
    "        step_size: size of each move in each attack step \n",
    "        clip_value_min, clip_value_max: range of valid input \n",
    "        from_logits = True: attack from logits otherwise attack from prediction probabilites\n",
    "    Note: \n",
    "        we expect the output of model should be logits vector  \n",
    "    \"\"\"       \n",
    "    \n",
    "    loss_fn = tf.keras.losses.sparse_categorical_crossentropy  #compute CE loss from logits or prediction probabilities\n",
    "    \n",
    "    if type(input_image) is np.ndarray: \n",
    "        input_image = tf.convert_to_tensor(input_image)\n",
    "    \n",
    "    if type(input_label) is np.ndarray: \n",
    "        input_label = tf.convert_to_tensor(input_label)\n",
    "        \n",
    "    # random initialization around input_image \n",
    "    random_noise = tf.random.uniform(shape=input_image.shape, minval=-epsilon, maxval=epsilon)\n",
    "    adv_image = input_image + random_noise\n",
    "\n",
    "    for _ in range(num_steps): \n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape: \n",
    "            tape.watch(adv_image)\n",
    "            adv_output = model(adv_image)\n",
    "            if not soft_label:\n",
    "                loss = loss_fn(input_label, adv_output, from_logits= from_logits) # use ground-truth label to attack\n",
    "            else: \n",
    "                pred_label = tf.math.argmax(adv_output, axis=1)\n",
    "                loss = loss_fn(pred_label, adv_output, from_logits= from_logits) # use predicted label to attack\n",
    "\n",
    "        gradient = tape.gradient(loss, adv_image) # get the gradient of the loss w.r.t. the current point \n",
    "        adv_image = adv_image + step_size * tf.sign(gradient) # move current adverarial example along the gradient direction with step size is eta \n",
    "        adv_image = tf.clip_by_value(adv_image, input_image-epsilon, input_image+epsilon) # clip to a valid boundary  \n",
    "        adv_image = tf.clip_by_value(adv_image, clip_value_min, clip_value_max)  # clip to a valid range\n",
    "        adv_image = tf.stop_gradient(adv_image) # stop the gradient to make the adversarial image as a constant input \n",
    "    return adv_image\n",
    "\n",
    "\n",
    "def mim_attack(model, input_image, input_label= None, \n",
    "              epsilon=0.3, \n",
    "              gamma= 0.9,\n",
    "              num_steps=20, \n",
    "              step_size=0.01, \n",
    "              clip_value_min=0., \n",
    "              clip_value_max=1.0, \n",
    "              soft_label=False,\n",
    "              from_logits= True): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        model: pretrained model \n",
    "        input_image: original (clean) input image (tensor)\n",
    "        input_label: original label (tensor, categorical representation)\n",
    "        epsilon: perturbation boundary \n",
    "        gamma: momentum decay\n",
    "        num_steps: number of attack steps \n",
    "        step_size: size of each move in each attack step \n",
    "        clip_value_min, clip_value_max: range of valid input \n",
    "        from_logits = True: attack from logits otherwise attack from prediction probabilites\n",
    "    Note: \n",
    "        we expect the output of model should be logits vector  \n",
    "    \"\"\"       \n",
    "    \n",
    "    loss_fn = tf.keras.losses.sparse_categorical_crossentropy # compute CE loss from logits or prediction probabilities\n",
    "    \n",
    "    if type(input_image) is np.ndarray: \n",
    "        input_image = tf.convert_to_tensor(input_image)\n",
    "    \n",
    "    if type(input_label) is np.ndarray: \n",
    "        input_label = tf.convert_to_tensor(input_label)\n",
    "        \n",
    "    # random initialization around input_image \n",
    "    random_noise = tf.random.uniform(shape=input_image.shape, minval=-epsilon, maxval=epsilon)\n",
    "    adv_image = input_image + random_noise\n",
    "    adv_noise = random_noise\n",
    "\n",
    "    for _ in range(num_steps): \n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape: \n",
    "            tape.watch(adv_image)\n",
    "            adv_output = model(adv_image)\n",
    "            if not soft_label:\n",
    "                loss = loss_fn(input_label, adv_output, from_logits=from_logits) # use ground-truth label to attack\n",
    "            else: \n",
    "                pred_label = tf.math.argmax(adv_output, axis=1)\n",
    "                loss = loss_fn(pred_label, adv_output, from_logits=from_logits) # use predicted label to attack\n",
    "\n",
    "        gradient = tape.gradient(loss, adv_image) # get the gradient of the loss w.r.t. the current point \n",
    "        adv_image_new = adv_image + step_size * tf.sign(gradient) # move current adverarial example along the gradient direction with step size is eta \n",
    "        adv_image_new = tf.clip_by_value(adv_image_new, input_image-epsilon, input_image+epsilon) # clip to a valid boundary  \n",
    "        adv_image_new = tf.clip_by_value(adv_image_new, clip_value_min, clip_value_max) # clip to a valid range\n",
    "        adv_noise = gamma*adv_noise + (1-gamma)*(adv_image_new - adv_image)\n",
    "        adv_image = adv_image_new\n",
    "        adv_image = tf.stop_gradient(adv_image) # stop the gradient to make the adversarial image as a constant input \n",
    "    adv_image = adv_image + adv_noise\n",
    "    adv_image = tf.clip_by_value(adv_image, input_image-epsilon, input_image+epsilon) # clip to a valid boundary  \n",
    "    adv_image = tf.clip_by_value(adv_image, clip_value_min, clip_value_max) # clip to a valid range\n",
    "    return adv_image\n",
    "\n",
    "\n",
    "def fgsm_attack(model, input_image, input_label=None, \n",
    "               epsilon=0.3, \n",
    "               clip_value_min=0., \n",
    "               clip_value_max=1.0, \n",
    "               soft_label=False,\n",
    "               from_logits=True): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        model: pretrained model \n",
    "        input_image: original (clean) input image (tensor)\n",
    "        input_label: original label (tensor, categorical representation)\n",
    "        epsilon: perturbation boundary \n",
    "        clip_value_min, clip_value_max: range of valid input \n",
    "        from_logits = True: attack from logits otherwise attack from prediction probabilites\n",
    "    Note: \n",
    "        we expect the output of model should be logits vector \n",
    "    \"\"\"\n",
    "    \n",
    "    loss_fn = tf.keras.losses.sparse_categorical_crossentropy # compute CE loss from logits or prediction probabilities\n",
    "    \n",
    "    if type(input_image) is np.ndarray: \n",
    "        input_image = tf.convert_to_tensor(input_image)\n",
    "    \n",
    "    if type(input_label) is np.ndarray: \n",
    "        input_label = tf.convert_to_tensor(input_label)\n",
    "        \n",
    "    with tf.GradientTape() as tape: \n",
    "        tape.watch(input_image)\n",
    "        output = model(input_image)\n",
    "        if not soft_label:\n",
    "            loss = loss_fn(input_label, output, from_logits=from_logits) # use ground-truth label to attack\n",
    "        else: \n",
    "            pred_label = tf.math.argmax(output, axis=1) # use predicted label to attack\n",
    "            loss = loss_fn(pred_label, output, from_logits=from_logits)\n",
    "\n",
    "    gradient = tape.gradient(loss, input_image) # get the gradients of the loss w.r.t. the input image \n",
    "    adv_image = input_image + epsilon * tf.sign(gradient) # get the final adversarial examples \n",
    "    adv_image = tf.clip_by_value(adv_image, clip_value_min, clip_value_max) # clip to a valid range  \n",
    "    adv_image = tf.stop_gradient(adv_image) # stop the gradient to make the adversarial image as a constant input\n",
    "    return adv_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction counter / sum for different attack\n",
    "correct_prediction_pgd = 0\n",
    "correct_prediction_mim = 0\n",
    "correct_prediction_fgsm = 0\n",
    "\n",
    "# choose 20 samples from test cases\n",
    "random_indices = np.random.choice(data_manager.X_test.shape[0], size=20, replace=False)\n",
    "x = data_manager.X_test[random_indices]\n",
    "y = data_manager.y_test[random_indices]\n",
    "\n",
    "# original prediction without any adversarial attack\n",
    "x_ori = my_cnn_model.predict(x)\n",
    "\n",
    "# data for each adversarial attack\n",
    "x_pgd = pgd_attack(my_cnn_model.model, tf.cast(x, tf.float32), y, num_steps=20, step_size= 0.002, epsilon = 0.0313,\n",
    "                   soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "\n",
    "x_mim = mim_attack(my_cnn_model.model, tf.cast(x, tf.float32), y, num_steps=20, step_size= 0.002, epsilon = 0.0313,\n",
    "                   soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "\n",
    "x_fgsm = fgsm_attack(my_cnn_model.model, tf.cast(x, tf.float32), y, epsilon = 0.0313,\n",
    "                   soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "\n",
    "# prediction for each adversarial attack\n",
    "pgd_pred = my_cnn_model.predict(x_pgd)\n",
    "mim_pred = my_cnn_model.predict(x_mim)\n",
    "fgsm_pred = my_cnn_model.predict(x_fgsm)\n",
    "\n",
    "# plot the original, pgd, mim and fgsm images in their own row for every samples \n",
    "for j in range(20):\n",
    "    f, ax = plt.subplots(nrows=1, ncols=4, figsize=(9, 4)) \n",
    "    ax[0].set_title(\"Original\", fontsize=12)\n",
    "    ax[0].imshow(x[j])\n",
    "    ax[0].axis('off')\n",
    "    ax[1].set_title(\"PGD attack\", fontsize=12)\n",
    "    ax[1].imshow(x_pgd[j])\n",
    "    ax[1].axis('off')\n",
    "    ax[2].set_title(\"MIM attack\", fontsize=12)\n",
    "    ax[2].imshow(x_mim[j])\n",
    "    ax[2].axis('off')\n",
    "    ax[3].set_title(\"FGSM attack\", fontsize=12)\n",
    "    ax[3].imshow(x_fgsm[j])\n",
    "    ax[3].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # increment the counter if the corresponding prediction is the same\n",
    "    if pgd_pred[j] == x_ori[j]:\n",
    "        correct_prediction_pgd += 1\n",
    "    if mim_pred[j] == x_ori[j]:\n",
    "        correct_prediction_mim += 1\n",
    "    if fgsm_pred[j] == x_ori[j]:\n",
    "        correct_prediction_fgsm += 1\n",
    "        \n",
    "print(\"Accuracy for pgd attack: \", correct_prediction_pgd / 20)\n",
    "print(\"Accuracy for mim attack: \", correct_prediction_mim / 20)\n",
    "print(\"Accuracy for fgsm attack: \", correct_prediction_fgsm / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOQvjv70Kot2"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.7**</span> **Train a robust model using adversarial training with PGD ${\\epsilon= 0.0313, k=10, \\eta= 0.002}$. Write the code for the adversarial training and report the robust accuracies. After finishing the training, you need to store your best robust model in the folder `./models` and load the model to evaluate the robust accuracies for PGD, MIM, and FGSM attacks with $\\epsilon= 0.0313, k=20, \\eta= 0.002$ on the testing set.**\n",
    "   \n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[4 points]</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "loss_obj = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "\n",
    "# metrics to track the different accuracies.\n",
    "train_loss = tf.metrics.Mean(name='train_loss')\n",
    "test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_pgd = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def train_step_adv(x, x_adv, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = my_cnn_model.model(x)\n",
    "        logits_adv = my_cnn_model.model(x_adv)\n",
    "        loss = (loss_obj(y, logits) + loss_obj(y, logits_adv))/2\n",
    "        gradients = tape.gradient(loss, my_cnn_model.model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, my_cnn_model.model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "iteration_size = data_manager.X_train.shape[0] // batch_size\n",
    "remainder_size = data_manager.X_train.shape[0] % batch_size\n",
    "\n",
    "\n",
    "epochs = 10 # number of epochs\n",
    "for epoch in range(epochs):\n",
    "    # keras like display of progress\n",
    "    progress_bar_train = tf.keras.utils.Progbar(data_manager.X_train.shape[0], verbose=1)\n",
    "    for k in range(iteration_size+1):\n",
    "        # replace clean example with adversarial example by 10-steps projected_gradient_descent for adversarial training\n",
    "        # checking for batch_remainder\n",
    "        if k == iteration_size+1:\n",
    "            x,y = data_manager.next_batch(batch_size)\n",
    "        else:\n",
    "            x,y = data_manager.next_batch(remainder_size)\n",
    "            \n",
    "        if k != iteration_size+1 or remainder_size != 0: # skip when the batch_remainder == 0\n",
    "            x_pgd = pgd_attack(my_cnn_model.model, tf.cast(x, tf.float32), y, num_steps=10, step_size= 0.002, epsilon = 0.0313,\n",
    "                       soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "            loss = train_step_adv(x, x_pgd, y)\n",
    "\n",
    "            y_pred = my_cnn_model.model(x)\n",
    "            my_test_res = 0\n",
    "            test_acc_clean(y, y_pred)\n",
    "            test_acc_pgd(y, my_cnn_model.model(x_pgd))\n",
    "            train_loss(loss)\n",
    "            progress_bar_train.add(x.shape[0], values=[('loss', train_loss.result()), \n",
    "                                                       (\"acc (%)\", test_acc_clean.result() * 100),\n",
    "                                                    (\"pgd (%)\", test_acc_pgd.result() * 100)])\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "my_cnn_model.model.save(\"models/my_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# load model\n",
    "defense_cnn_model = load_model('models/my_cnn_model.h5', custom_objects={'ova_loss': ova_loss})\n",
    "\n",
    "# function to find the next batch of test samples\n",
    "def next_batch_test(self, batch_size=32):\n",
    "    idx = data_manager.random.choice(data_manager.X_test.shape[0], batch_size, \n",
    "                                     replace=batch_size > data_manager.X_test.shape[0])\n",
    "    return data_manager.X_test[idx], data_manager.y_test[idx]\n",
    "\n",
    "\n",
    "y_adv_pgd = []\n",
    "y_true_pgd = []\n",
    "y_adv_mim = []\n",
    "y_true_mim = []\n",
    "y_adv_fgsm = []\n",
    "y_true_fgsm = []\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "iteration_size = data_manager.X_test.shape[0] // batch_size\n",
    "\n",
    "\n",
    "# test\n",
    "for k in range(iteration_size):\n",
    "    # next batch of test cases\n",
    "    x,y = next_batch_test(batch_size)\n",
    "    \n",
    "    # input under adversarial attack\n",
    "    x_pgd = pgd_attack(defense_cnn_model, tf.cast(x, tf.float32), y, num_steps=20, step_size= 0.002, epsilon = 0.0313,\n",
    "               soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "    \n",
    "    x_mim = mim_attack(defense_cnn_model, tf.cast(x, tf.float32), y, num_steps=20, step_size= 0.002, epsilon = 0.0313,\n",
    "                   soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "\n",
    "    x_fgsm = fgsm_attack(defense_cnn_model, tf.cast(x, tf.float32), y, epsilon = 0.0313,\n",
    "                       soft_label=False, clip_value_min=0.0, clip_value_max=255.0, from_logits=False)\n",
    "    \n",
    "    # pgd\n",
    "    y_batch_adv_pgd = np.argmax(defense_cnn_model(x_pgd).numpy(), 1)\n",
    "    y_adv_pgd.append(y_batch_adv_pgd[0].tolist())\n",
    "    y_true_pgd.append(y[0].tolist())\n",
    "    \n",
    "    # mim\n",
    "    y_batch_adv_mim = np.argmax(defense_cnn_model(x_mim).numpy(), 1)\n",
    "    y_adv_mim.append(y_batch_adv_mim[0].tolist())\n",
    "    y_true_mim.append(y[0].tolist())\n",
    "    \n",
    "    # fgsm\n",
    "    y_batch_adv_fgsm = np.argmax(defense_cnn_model(x_fgsm).numpy(), 1)\n",
    "    y_adv_fgsm.append(y_batch_adv_fgsm[0].tolist())\n",
    "    y_true_fgsm.append(y[0].tolist())\n",
    "\n",
    "    \n",
    "test_adv_acc_pgd = accuracy_score(y_true_pgd, y_adv_pgd)\n",
    "print(\"Test adv under pgd attack accuracy:{}\".format(test_adv_acc_pgd))\n",
    "test_adv_acc_mim = accuracy_score(y_true_mim, y_adv_mim)\n",
    "print(\"Test adv under mim attack accuracy:{}\".format(test_adv_acc_mim))\n",
    "test_adv_acc_fgsm = accuracy_score(y_true_fgsm, y_adv_fgsm)\n",
    "print(\"Test adv under fgsm attack accuracy:{}\".format(test_adv_acc_fgsm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oYstI7TKot2"
   },
   "source": [
    "<span style=\"color:red\">**Question 3.8 (Kaggle competition)**</span>\n",
    "<div style=\"text-align: right\"> <span style=\"color:red\">[10 points]</span> </div10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b56nVcJBKot3"
   },
   "source": [
    "You can reuse the best model obtained in this assignment or develop new models to evaluate on the **testing set of the FIT5215 Kaggle competion**. However, to gain any points for this question, your testing accuracy must **exceed** the accuracy threshold from a base model developed by us as shown in the leader board of the competition.\n",
    "\n",
    "The marks for this question are as follows:\n",
    "- If you are in *top 10%*, you gain *10 points*.\n",
    "- If you are in *top 20%*, you gain *8 points*.\n",
    "- If you are in *top 30%*, you gain *6 points*.\n",
    "- If you *win* our base model, you gain *4 points*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCpwgiKFKot3"
   },
   "source": [
    "<span style=\"color:green\">**Tips and requirements**</span>\n",
    "- Your **team name** or **member name** using in this Kaggle competion must contain your student ID, which faciliates us in marking this question.\n",
    "- You can use any deep/machine techniques in this Kaggle competition.\n",
    "- We apply some slight transformations and add noises to unseen testing images to make the task more challenging. There is a slight shift between training distribution and testing distribution.\n",
    "- You must submit your code, trained model, and a brief document decribed your method followed a provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U4xpJfzKot3"
   },
   "source": [
    "---\n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">END OF ASSIGNMENT</span> </div>**\n",
    "**<div style=\"text-align: center\"> <span style=\"color:black\">GOOD LUCK WITH YOUR ASSIGNMENT 1!</span> </div>**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
